{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximusThomas/ML-Projects/blob/main/convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network From Scratch\n",
        "\n",
        "Binary classification CNN using just NumPy, linear algebra, and calculus with no PyTorch or TensorFlow.\n",
        "\n",
        "Fully vectorized to ensure efficient inference and training.\n",
        "\n",
        "[GitHub repo](https://github.com/MaximusThomas/ML-Projects)"
      ],
      "metadata": {
        "id": "XCgpaUX6H7cd"
      },
      "id": "XCgpaUX6H7cd"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "79a86001",
      "metadata": {
        "id": "79a86001"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0ff7447e",
      "metadata": {
        "id": "0ff7447e"
      },
      "outputs": [],
      "source": [
        "def convolution(A_prev, filters, biases, n_s, n_p):\n",
        "    '''\n",
        "    Single convolutional layer of all filters, assuming ReLU activation\n",
        "\n",
        "    Args:\n",
        "        A_prev ((m, n_H, n_W, n_C)): matrix of activations\n",
        "        filters ((n_filters, n_f, n_f, n_C)): filters\n",
        "        biases (n_filters): bias term for each filter\n",
        "        n_s (int): convolution stride\n",
        "        n_p (int): amount of padding (assumes square symmetrical)\n",
        "\n",
        "    Returns:\n",
        "        A_next ((m, n_H_, n_W_, n_filters)): output matrix of activations\n",
        "        cache (dict): Python dictionary containing keys \"A_prev\", \"filters\", \"biases\", \"stride\", \"padding\"\n",
        "    '''\n",
        "\n",
        "    # Get filter shape and activation height and width\n",
        "    n_f, n_filters = filters.shape[1], filters.shape[0]\n",
        "    m, n_H, n_W = A_prev.shape[0], A_prev.shape[1], A_prev.shape[2]\n",
        "\n",
        "    # Calculate output height and width\n",
        "    n_H_ = int(np.floor((n_H + (2 * n_p) - n_f) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W + (2 * n_p) - n_f) / n_s)) + 1\n",
        "\n",
        "    # Pad the input activation matrix\n",
        "    A_prev_pad = np.pad(A_prev,\n",
        "                        pad_width=((0, 0), (n_p, n_p), (n_p, n_p), (0, 0)),\n",
        "                        mode='constant')\n",
        "\n",
        "    Z = np.zeros((m, n_H_, n_W_, n_filters))\n",
        "\n",
        "    # Cache required values\n",
        "    cache = {}\n",
        "    cache['A_prev'], cache['filters'], cache['biases'] = A_prev, filters, biases\n",
        "    cache['stride'], cache['padding'] = n_s, n_p\n",
        "\n",
        "    # Loop over all examples\n",
        "    for i in range(m):\n",
        "\n",
        "        # Loop over all filter positions\n",
        "        for h in range(n_H_):\n",
        "            for w in range(n_W_):\n",
        "\n",
        "                # Loop over all filters; returns filter of shape (n_f, n_f, n_C)\n",
        "                for filter_idx, (bias, filter) in enumerate(zip(biases, filters)):\n",
        "\n",
        "                    # Calculate indices for activation matrix slicing\n",
        "                    vert_start = h * n_s\n",
        "                    vert_end = vert_start + n_f\n",
        "                    horiz_start = w * n_s\n",
        "                    horiz_end = horiz_start + n_f\n",
        "\n",
        "                    # Element-wise multiplication and\n",
        "                    z = (A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :] *  filter) + bias\n",
        "                    z = np.sum(z)\n",
        "                    Z[i, h, w, filter_idx] = z\n",
        "\n",
        "\n",
        "    cache['Z'] = Z\n",
        "    # ReLU activation function\n",
        "    A_next = np.maximum(Z, 0)\n",
        "    cache['A_next'] = A_next\n",
        "\n",
        "    return A_next, cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorized_convolution(A_prev, filters, biases, n_s, n_p):\n",
        "    '''\n",
        "    Single convolutional layer of all filters, assuming ReLU activation\n",
        "\n",
        "    Args:\n",
        "        A_prev ((m, n_H, n_W, n_C)): matrix of activations\n",
        "        filters ((n_filters, n_f, n_f, n_C)): filters\n",
        "        biases (n_filters): bias term for each filter\n",
        "        n_s (int): convolution stride\n",
        "        n_p (int): amount of padding (assumes square symmetrical)\n",
        "\n",
        "    Returns:\n",
        "        A_next ((m, n_H_, n_W_, n_filters)): output matrix of activations\n",
        "        cache (dict): Python dictionary containing keys \"A_prev\", \"A_next\", \"filters\", \"biases\", \"stride\", \"padding\", \"Z\"\n",
        "    '''\n",
        "    # Get filter shape and activation height and width\n",
        "    n_f, n_filters = filters.shape[1], filters.shape[0]\n",
        "    (m, n_H, n_W, n_C) = A_prev.shape\n",
        "\n",
        "    # Calculate output height and width\n",
        "    n_H_ = int(np.floor((n_H + (2 * n_p) - n_f) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W + (2 * n_p) - n_f) / n_s)) + 1\n",
        "\n",
        "    # Pad the input activation matrix\n",
        "    A_prev_pad = np.pad(A_prev,\n",
        "                        pad_width=((0, 0), (n_p, n_p), (n_p, n_p), (0, 0)),\n",
        "                        mode='constant')\n",
        "\n",
        "    # Cache required values\n",
        "    cache = {}\n",
        "    cache['A_prev'], cache['filters'], cache['biases'] = A_prev, filters, biases\n",
        "    cache['stride'], cache['padding'] = n_s, n_p\n",
        "\n",
        "    # Create view of sliding windows\n",
        "    shape = (m, n_H_, n_W_, n_f, n_f, n_C)\n",
        "    strides = (A_prev_pad.strides[0],\n",
        "               n_s * A_prev_pad.strides[1],\n",
        "               n_s * A_prev_pad.strides[2],\n",
        "               A_prev_pad.strides[1],\n",
        "               A_prev_pad.strides[2],\n",
        "               A_prev_pad.strides[3])\n",
        "\n",
        "    # Create windows matrix\n",
        "    windows = np.lib.stride_tricks.as_strided(A_prev_pad, shape=shape, strides=strides)\n",
        "\n",
        "    # Reshape for matmul\n",
        "    A_reshaped = windows.reshape(m * n_H_ * n_W_, -1)\n",
        "    filters_reshaped = filters.reshape(n_filters, -1)\n",
        "    cache['A_reshaped'] = A_reshaped\n",
        "\n",
        "    # Matrix multiplication and bias terms\n",
        "    Z = np.dot(filters_reshaped, A_reshaped.T) + biases.reshape(-1, 1)\n",
        "\n",
        "    # Reshape and traspose\n",
        "    Z_reshaped = Z.reshape(n_filters, m, n_H_, n_W_).transpose(1, 2, 3, 0)\n",
        "\n",
        "    # ReLU activation function\n",
        "    A_next = np.maximum(Z_reshaped, 0)\n",
        "\n",
        "    # Cache important values for backprop\n",
        "    cache['A_next'], cache['Z'] = A_next, Z_reshaped\n",
        "\n",
        "    return A_next, cache"
      ],
      "metadata": {
        "id": "oYwxSO2G7g2b"
      },
      "id": "oYwxSO2G7g2b",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c024408e",
      "metadata": {
        "id": "c024408e"
      },
      "outputs": [],
      "source": [
        "def max_pool(A_prev, pool_size, n_s):\n",
        "    '''\n",
        "    Max pooling step across all examples and filters\n",
        "\n",
        "    Args:\n",
        "        A_prev ((m, n_H, n_W, n_C)): matrix of activations\n",
        "        pool_size (int): size of pool, assuming square\n",
        "        n_s (int): stride\n",
        "\n",
        "    Returns:\n",
        "        A_next ((m, n_H_, n_W_, n_filters)): pooled output matrix of activations\n",
        "        cache (dict): Python dictionary containing keys \"A_prev\", \"pool_size\", \"stride\"\n",
        "    '''\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    m, n_H, n_W, n_C = A_prev.shape[0], A_prev.shape[1], A_prev.shape[2], A_prev.shape[3]\n",
        "    n_H_, n_W_ = int(np.floor((n_H - pool_size) / n_s)) + 1, int(np.floor((n_W - pool_size) / n_s)) + 1\n",
        "\n",
        "    A_next = np.zeros((m, n_H_, n_W_, n_C))\n",
        "    mask = np.zeros_like(A_prev)\n",
        "\n",
        "    # Cache values for backprop\n",
        "    cache = {}\n",
        "    cache['A_prev'], cache['pool_size'], cache['stride'] = A_prev, pool_size, n_s\n",
        "    # Loop over training examples\n",
        "    for i in range(m):\n",
        "\n",
        "        # Loop over all pooling positions\n",
        "        for h in range(int(n_H_)):\n",
        "            for w in range(int(n_W_)):\n",
        "\n",
        "                # Calculate indices for activation matrix slicing\n",
        "                vert_start = h * n_s\n",
        "                vert_end = vert_start + pool_size\n",
        "                horiz_start = w * n_s\n",
        "                horiz_end = horiz_start + pool_size\n",
        "\n",
        "                # Take np.max() across channels returning a vector and add into A_next\n",
        "                window = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                A_next[i, h, w, :] = np.max(window, axis=(0, 1))\n",
        "\n",
        "                # Create mask for backpropagation\n",
        "                mask_slice = (window == np.max(window, axis=(0, 1), keepdims=True))\n",
        "                mask[i, vert_start:vert_end, horiz_start:horiz_end, :] = mask_slice\n",
        "\n",
        "    cache['mask'] = mask\n",
        "    return A_next, cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_pool_vectorized(A_prev, pool_size, n_s):\n",
        "    '''\n",
        "    Max pooling step across all examples and filters\n",
        "\n",
        "    Args:\n",
        "        A_prev ((m, n_H, n_W, n_C)): matrix of activations\n",
        "        pool_size (int): size of pool, assuming square\n",
        "        n_s (int): stride\n",
        "\n",
        "    Returns:\n",
        "        A_next ((m, n_H_, n_W_, n_filters)): pooled output matrix of activations\n",
        "        cache (dict): Python dictionary containing keys \"A_prev\", \"pool_size\", \"stride\"\n",
        "    '''\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    (m, n_H, n_W, n_C) = A_prev.shape\n",
        "    n_H_ = int(np.floor((n_H - pool_size) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W - pool_size) / n_s)) + 1\n",
        "\n",
        "    # Cache values for backprop\n",
        "    cache = {}\n",
        "    cache['A_prev'], cache['pool_size'], cache['stride'] = A_prev, pool_size, n_s\n",
        "\n",
        "    # Create windows\n",
        "    shape = (m, n_H_, n_W_, pool_size, pool_size, n_C)\n",
        "    strides = (A_prev.strides[0],\n",
        "               n_s * A_prev.strides[1],\n",
        "               n_s * A_prev.strides[2],\n",
        "               A_prev.strides[1],\n",
        "               A_prev.strides[2],\n",
        "               A_prev.strides[3])\n",
        "\n",
        "    windows = np.lib.stride_tricks.as_strided(A_prev, shape, strides)\n",
        "\n",
        "    # Take max over each max pooling position\n",
        "    A_next = np.max(windows.reshape(m, n_H_, n_W_, pool_size * pool_size, n_C), axis=3)\n",
        "\n",
        "    return A_next, cache\n"
      ],
      "metadata": {
        "id": "k5V90cxLAwEk"
      },
      "id": "k5V90cxLAwEk",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a07b70ff",
      "metadata": {
        "id": "a07b70ff"
      },
      "outputs": [],
      "source": [
        "def conv_back_prop(dA_next, cache):\n",
        "    '''\n",
        "    Back prop for a single convolution layer\n",
        "\n",
        "    Args:\n",
        "        dZ ((m, n_H_, n_W_, n_filters)): gradient of linear dot product output\n",
        "        cache (): cache of A_prev, filters (weights), stride, and padding\n",
        "    '''\n",
        "\n",
        "    # Obtain required variables from layer cache\n",
        "    Z_linear_output = cache['Z']\n",
        "    A_prev = cache['A_prev']\n",
        "    filters = cache['filters']\n",
        "    n_s = cache['stride']\n",
        "    n_p = cache['padding']\n",
        "    A_next = cache['A_next']\n",
        "\n",
        "    # Get shapes\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    n_filters, n_f, _, _ = filters.shape\n",
        "\n",
        "    dZ = dA_next * (A_next > 0)\n",
        "    m_dZ, n_H_out, n_W_out, _ = dZ.shape\n",
        "\n",
        "    # Initialize gradients\n",
        "    db = np.zeros((n_filters))\n",
        "    dW = np.zeros_like(filters) # dW has shape (n_filters, n_f, n_f, n_C_prev)\n",
        "    dA_prev = np.zeros_like(A_prev) # dA_prev has shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "\n",
        "    # Pad dA_prev for gradient accumulation\n",
        "    dA_prev_pad = np.pad(dA_prev,\n",
        "                         pad_width=((0, 0), (n_p, n_p), (n_p, n_p), (0, 0)),\n",
        "                         mode='constant')\n",
        "\n",
        "    # Pad A_prev for calculations (this is the A_prev_pad used in forward pass)\n",
        "    A_prev_padded = np.pad(A_prev,\n",
        "                         pad_width=((0, 0), (n_p, n_p), (n_p, n_p), (0, 0)),\n",
        "                         mode='constant')\n",
        "\n",
        "    # Loop over all training examples\n",
        "    for i in range(m):\n",
        "        # Loop over output positions\n",
        "        for h_out in range(n_H_out):\n",
        "            for w_out in range(n_W_out):\n",
        "                vert_start = h_out * n_s\n",
        "                vert_end = vert_start + n_f\n",
        "                horiz_start = w_out * n_s\n",
        "                horiz_end = horiz_start + n_f\n",
        "\n",
        "                # Slice the relevant window from A_prev_padded\n",
        "                A_prev_window = A_prev_padded[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                # Loop over all filters\n",
        "                for filter_idx in range(n_filters):\n",
        "                    current_filter = filters[filter_idx, :, :, :] # Shape (n_f, n_f, n_C_prev)\n",
        "\n",
        "                    # Accumulate gradient for A_prev_pad\n",
        "                    # dL/dA_prev_element += dL/dZ_element * W_element\n",
        "                    dA_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :] += \\\n",
        "                        current_filter * dZ[i, h_out, w_out, filter_idx]\n",
        "\n",
        "                    # Accumulate gradient for W (filters)\n",
        "                    # dL/dW_element += A_prev_element * dL/dZ_element\n",
        "                    dW[filter_idx, :, :, :] += A_prev_window * dZ[i, h_out, w_out, filter_idx]\n",
        "\n",
        "                    # Accumulate gradient for b (bias)\n",
        "                    # dL/db_element += dL/dZ_element\n",
        "                    db[filter_idx] += dZ[i, h_out, w_out, filter_idx]\n",
        "\n",
        "    # Unpad dA_prev_pad to get dA_prev (gradient w.r.t. unpadded input to this layer)\n",
        "    if n_p > 0:\n",
        "        dA_prev = dA_prev_pad[:, n_p:-n_p, n_p:-n_p, :]\n",
        "    else:\n",
        "        dA_prev = dA_prev_pad\n",
        "\n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vec_conv_back_prop(dA_next, cache):\n",
        "    '''\n",
        "    Back prop for a single convolution layer\n",
        "\n",
        "    Args:\n",
        "        dA ((m, n_H_, n_W_, n_filters)): gradient of ReLU activations\n",
        "        cache (): cache of A_prev, filters (weights), stride, and padding\n",
        "    '''\n",
        "\n",
        "    # Retrieve cached values\n",
        "    A_prev = cache['A_prev']\n",
        "    W = cache['filters']\n",
        "    n_f = W.shape[1]\n",
        "    n_s = cache['stride']\n",
        "    n_p = cache['padding']\n",
        "    Z = cache['Z']\n",
        "    A_reshaped = cache['A_reshaped'] # A_reshaped is (m * n_H_out * n_W_out, n_f * n_f * n_C) from forward pass\n",
        "\n",
        "    # Differentiate with respect to linear activations\n",
        "    dZ = dA_next * (Z > 0)\n",
        "\n",
        "    # Reshape for im2col matrix multiplication\n",
        "    n_filters = W.shape[0] # Get n_filters from W shape\n",
        "    m, n_H_out, n_W_out, _ = dZ.shape # Use dZ's actual shape for output dimensions\n",
        "\n",
        "    dZ_reshaped = dZ.transpose(3, 0, 1, 2).reshape(n_filters, -1) # (n_filters, m * n_H_out * n_W_out)\n",
        "\n",
        "    # Differentiate with respect to dW and db\n",
        "    # dW should be (n_filters, n_f, n_f, n_C)\n",
        "    # A_reshaped is (m * n_H_out * n_W_out, n_f * n_f * n_C)\n",
        "    dW = np.dot(dZ_reshaped, A_reshaped).reshape(W.shape)\n",
        "    db = np.sum(dZ, axis=(0, 1, 2)).reshape(n_filters, 1, 1)\n",
        "\n",
        "    # Propagate gradient back to input activations\n",
        "    W_reshaped = W.reshape(n_filters, -1) # (n_filters, n_f * n_f * n_C)\n",
        "    dA_prev_reshaped = np.dot(W_reshaped.T, dZ_reshaped) # (n_f * n_f * n_C, m * n_H_out * n_W_out)\n",
        "\n",
        "    # col2im\n",
        "    (m_A, n_H_A, n_W_A, n_C_A) = A_prev.shape\n",
        "    dA_prev_pad = np.zeros((m_A, n_H_A + (2 * n_p), n_W_A + (2 * n_p), n_C_A))\n",
        "\n",
        "    # Reshape dA_prev_reshaped to match the windowed view from forward pass gradients\n",
        "    # dA_prev_reshaped is (n_f * n_f * n_C_A, m * n_H_out * n_W_out)\n",
        "    # We need it to be (m, n_H_out, n_W_out, n_f, n_f, n_C_A) to add back to dA_prev_pad\n",
        "    d_windows = dA_prev_reshaped.T.reshape(m_A, n_H_out, n_W_out, n_f, n_f, n_C_A)\n",
        "\n",
        "    # Iterate and sum overlapping gradients\n",
        "    for i_ex in range(m_A):\n",
        "        for h_out in range(n_H_out):\n",
        "            for w_out in range(n_W_out):\n",
        "                vert_start = h_out * n_s\n",
        "                vert_end = vert_start + n_f\n",
        "                horiz_start = w_out * n_s\n",
        "                horiz_end = horiz_start + n_f\n",
        "\n",
        "                # Add the gradients from this window to the corresponding slice of dA_prev_pad\n",
        "                dA_prev_pad[i_ex, vert_start:vert_end, horiz_start:horiz_end, :] += d_windows[i_ex, h_out, w_out, :, :, :]\n",
        "\n",
        "    # Remove padding\n",
        "    if n_p > 0:\n",
        "        dA_prev = dA_prev_pad[:, n_p:-n_p, n_p:-n_p, :]\n",
        "    else:\n",
        "        dA_prev = dA_prev_pad\n",
        "\n",
        "    return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "N2f4qPSBCpSJ"
      },
      "id": "N2f4qPSBCpSJ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1cd54080",
      "metadata": {
        "id": "1cd54080"
      },
      "outputs": [],
      "source": [
        "def max_pool_backprop(dA_next, A_prev, pool_size, n_s, mask):\n",
        "    '''\n",
        "    Backprop for a max pooling layer\n",
        "\n",
        "    Args:\n",
        "        dA_next ((m, n_H_, n_W_, n_filters)): tensor of activations from max pooling layer\n",
        "        pool_size (int): size of pool, assuming square\n",
        "        n_s (int): stride\n",
        "        mask ((m, n_H, n_W, n_C)): tensor of either 0s or 1s corresponding to indices of max values\n",
        "\n",
        "    Returns:\n",
        "        dA_prev ((m, n_H, n_W, n_C)): tensor of activations from previous conv layer\n",
        "    '''\n",
        "\n",
        "    (m, n_H_, n_W_, n_C_) = dA_next.shape\n",
        "    dA_prev = np.zeros_like(A_prev)\n",
        "\n",
        "    # Loop over training examples\n",
        "    for i in range(m):\n",
        "\n",
        "        # Loop over dimensions\n",
        "        for h in range(n_H_):\n",
        "            for w in range(n_W_):\n",
        "\n",
        "                # Get window positions\n",
        "                vert_start = h * n_s\n",
        "                vert_end = vert_start + pool_size\n",
        "                horiz_start = h * n_s\n",
        "                horiz_end = horiz_start + pool_size\n",
        "\n",
        "                dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, :] += mask[i, vert_start:vert_end, horiz_start:horiz_end, :] * dA_next[i, h, w, :]\n",
        "\n",
        "    return dA_prev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vec_max_pool_backprop(dA_next, A_prev, pool_size, n_s):\n",
        "  '''\n",
        "  Backprop for a max pooling layer\n",
        "\n",
        "  Args:\n",
        "      dA_next ((m, n_H_, n_W_, n_filters)): tensor of activations from max pooling layer\n",
        "      pool_size (int): size of pool, assuming square\n",
        "      n_s (int): stride\n",
        "\n",
        "  Returns:\n",
        "      dA_prev ((m, n_H, n_W, n_C)): tensor of activations from previous conv layer\n",
        "  '''\n",
        "\n",
        "  # Retrieve shapes\n",
        "  # dA_next is (m, n_H_out, n_W_out, n_C) from full_backprop after reshape\n",
        "  (m, n_H_out, n_W_out, n_C) = dA_next.shape\n",
        "  (m_A_prev, n_H_A_prev, n_W_A_prev, n_C_A_prev) = A_prev.shape\n",
        "\n",
        "  # Calculate output dimensions for pooling based on A_prev\n",
        "  n_H_pool = int(np.floor((n_H_A_prev - pool_size) / n_s)) + 1\n",
        "  n_W_pool = int(np.floor((n_W_A_prev - pool_size) / n_s)) + 1\n",
        "\n",
        "  # Create windows view on A_prev for mask generation\n",
        "  shape_windows = (m_A_prev, n_H_pool, n_W_pool, pool_size, pool_size, n_C_A_prev)\n",
        "  strides_windows = (A_prev.strides[0],\n",
        "                     n_s * A_prev.strides[1],\n",
        "                     n_s * A_prev.strides[2],\n",
        "                     A_prev.strides[1],\n",
        "                     A_prev.strides[2],\n",
        "                     A_prev.strides[3])\n",
        "  windows = np.lib.stride_tricks.as_strided(A_prev, shape=shape_windows, strides=strides_windows)\n",
        "\n",
        "  # Create mask for max values (indices where max was taken in forward pass)\n",
        "  A_prev_flat = windows.reshape(m_A_prev, n_H_pool, n_W_pool, pool_size * pool_size, n_C_A_prev)\n",
        "  max_vals = np.max(A_prev_flat, axis=3, keepdims=True)\n",
        "  mask = (A_prev_flat == max_vals) # Shape (m, n_H_pool, n_W_pool, pool_size*pool_size, n_C)\n",
        "\n",
        "  # Reshape dA_next for broadcasting with mask\n",
        "  dA_next_reshaped_for_mask = dA_next[:, :, :, np.newaxis, :] # (m, n_H_out, n_W_out, 1, n_C)\n",
        "\n",
        "  # Apply mask to distribute gradients only to the maximum elements\n",
        "  dA_col_flat = mask * dA_next_reshaped_for_mask # (m, n_H_pool, n_W_pool, pool_size*pool_size, n_C)\n",
        "  dA_col = dA_col_flat.reshape(m_A_prev, n_H_pool, n_W_pool, pool_size, pool_size, n_C_A_prev) # (m, n_H_pool, n_W_pool, pool_size, pool_size, n_C)\n",
        "\n",
        "  # col2im: Initialize dA_prev with zeros, then accumulate gradients\n",
        "  dA_prev = np.zeros_like(A_prev)\n",
        "\n",
        "  for i_ex in range(m_A_prev):\n",
        "    for h_out in range(n_H_pool):\n",
        "      for w_out in range(n_W_pool):\n",
        "        vert_start = h_out * n_s\n",
        "        vert_end = vert_start + pool_size\n",
        "        horiz_start = w_out * n_s\n",
        "        horiz_end = horiz_start + pool_size\n",
        "\n",
        "        # Add the gradients for this specific window back into dA_prev\n",
        "        dA_prev[i_ex, vert_start:vert_end, horiz_start:horiz_end, :] += dA_col[i_ex, h_out, w_out, :, :, :]\n",
        "\n",
        "  return dA_prev"
      ],
      "metadata": {
        "id": "9LwrHPFwDHZ4"
      },
      "id": "9LwrHPFwDHZ4",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7d6641d9",
      "metadata": {
        "id": "7d6641d9"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "\n",
        "    x = np.clip(x, -500, 500)\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7c6b8cf4",
      "metadata": {
        "id": "7c6b8cf4"
      },
      "outputs": [],
      "source": [
        "def binary_cross_entropy_cost(yhat, y, epsilon = 1e-15):\n",
        "\n",
        "    m = y.shape[1]\n",
        "    yhat = np.clip(yhat, epsilon, 1 - epsilon)\n",
        "    cost = -1/m * np.sum((y * np.log(yhat)) + ((1-y) * np.log(1-yhat)))\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8723fdb9",
      "metadata": {
        "id": "8723fdb9"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(X, dense_dims, conv_params, conv_dims):\n",
        "\n",
        "    m = X.shape[0]\n",
        "    A_prev = X\n",
        "    l = 1\n",
        "    for dim in conv_dims:\n",
        "\n",
        "      if dim == 'conv':\n",
        "\n",
        "        # Single convolutional layer with ReLU activation\n",
        "        A_next, _ = convolution(A_prev,\n",
        "                                    filters=conv_params['W' + str(l)],\n",
        "                                    biases=conv_params['b' + str(l)],\n",
        "                                    n_s=conv_dims[dim]['n_s'],\n",
        "                                    n_p=conv_dims[dim]['n_p'])\n",
        "        l += 1\n",
        "\n",
        "      elif dim == 'max_pool':\n",
        "        A_next, _ = max_pool(A_prev, conv_dims[dim]['pool_size'], conv_dims[dim]['n_s'])\n",
        "\n",
        "      A_prev = A_next\n",
        "\n",
        "    dense_dims.insert(0, A_prev.reshape(-1, m).shape[0])\n",
        "\n",
        "    parameters = {}\n",
        "    for l in range(1, len(dense_dims)):\n",
        "        parameters['W' + str(l)] = np.random.randn(dense_dims[l], dense_dims[l - 1]) * np.sqrt(2/dense_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((dense_dims[l], 1))\n",
        "\n",
        "    return parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5819464c",
      "metadata": {
        "id": "5819464c"
      },
      "outputs": [],
      "source": [
        "def dense_forward_prop(conv_prev, y, parameters):\n",
        "    '''\n",
        "    Forward prop for dense layers, flattening convolutional output, assuming ReLU activation and sigmoid output activation\n",
        "\n",
        "    Args:\n",
        "        conv_prev ((m, n_H, n_W, n_filters)): tensor of activations from final max pooling layer\n",
        "        parameters (dict): dictionary containing all dense network parameters\n",
        "            W ((n_l, n_l_prev)): matrix of weights\n",
        "            b ((n_l, 1)): column vector of bias terms\n",
        "        y ((1, m)): labels\n",
        "\n",
        "    Returns:\n",
        "        yhat ((1, m)): predictions from forward prop\n",
        "    '''\n",
        "\n",
        "    # Flatten A_prev into a 2D matrix\n",
        "    m = conv_prev.shape[0]\n",
        "    A_prev = conv_prev.reshape(-1, m)\n",
        "\n",
        "    # Forward prop through dense network\n",
        "    caches = []\n",
        "    L = len(parameters) // 2\n",
        "    for l in range(1, L):\n",
        "        cache = {}\n",
        "\n",
        "        # Calculate linear product\n",
        "        Z = np.dot(parameters['W' + str(l)], A_prev) + parameters['b' + str(l)]\n",
        "        cache['Z' + str(l)] = Z\n",
        "        cache['W' + str(l)] = parameters['W' + str(l)]\n",
        "\n",
        "        # Apply activation function\n",
        "        A_next = np.maximum(Z, 0)\n",
        "        cache['A' + str(l-1)] = A_prev\n",
        "        A_prev = A_next\n",
        "\n",
        "        # Append cache\n",
        "        caches.append(cache)\n",
        "\n",
        "    # Output layer\n",
        "    cache = {}\n",
        "    cache['A' + str(L-1)] = A_prev\n",
        "    Z = np.dot(parameters['W' + str(L)], A_prev) + parameters['b' + str(L)]\n",
        "    cache['Z' + str(L)] = Z\n",
        "    cache['W' + str(L)] = parameters['W' + str(L)]\n",
        "    caches.append(cache)\n",
        "    yhat = sigmoid(Z)\n",
        "\n",
        "    # Calculate loss\n",
        "    cost = binary_cross_entropy_cost(yhat, y)\n",
        "\n",
        "    return cost, yhat, caches\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "cc2415a6",
      "metadata": {
        "id": "cc2415a6"
      },
      "outputs": [],
      "source": [
        "def dense_backprop(yhat, y, caches):\n",
        "    '''\n",
        "    Backprop for dense layers, assuming ReLU activation and sigmoid output activation\n",
        "\n",
        "    Args:\n",
        "        yhat ((1, m)): vector of activations of output layer for each example\n",
        "        y ((1, m)): vector of labels for each training example\n",
        "        caches (list): list of each layer's cache dictionary\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    '''\n",
        "\n",
        "    m = yhat.shape[1]\n",
        "    grads = {}\n",
        "    L = len(caches)\n",
        "\n",
        "    # Backprop for output layer\n",
        "    cache = caches[-1]\n",
        "    grads['dZ' + str(L)] = yhat - y\n",
        "    grads['dW' + str(L)] = 1/m * np.dot(grads['dZ' + str(L)], cache['A' + str(L-1)].T)\n",
        "    grads['db' + str(L)] = 1/m * np.sum(grads['dZ' + str(L)], axis=1, keepdims=True)\n",
        "    grads['dA' + str(L-1)] = np.dot(cache['W' + str(L)].T, grads['dZ' + str(L)])\n",
        "\n",
        "    # Backprop for hidden layers\n",
        "    for l in range(L-1, 0, -1):\n",
        "\n",
        "        cache = caches[l-1]\n",
        "        grads['dZ' + str(l)] = grads['dA' + str(l)] * (cache['Z' + str(l)] > 0)\n",
        "        grads['dW' + str(l)] = 1/m * np.dot(grads['dZ' + str(l)], cache['A' + str(l-1)].T)\n",
        "        grads['db' + str(l)] = 1/m * np.sum(grads['dZ' + str(l)], axis=1, keepdims=True)\n",
        "        grads['dA' + str(l-1)] = np.dot(cache['W' + str(l)].T, grads['dZ' + str(l)])\n",
        "\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c84f820f",
      "metadata": {
        "id": "c84f820f"
      },
      "outputs": [],
      "source": [
        "def initialize_convolution(X, conv_dims):\n",
        "    '''\n",
        "    Initializes parameters for convolutional part of network\n",
        "\n",
        "    Args:\n",
        "        X (((m, n_H, n_W, n_C)): input matrix\n",
        "        conv_dims (dict): dict containing either 'conv', or 'max_pool' corresponding to a sub-dict\n",
        "            conv (dict): dict with keys 'n_f', 'n_s', 'n_p', 'n_filters'\n",
        "                n_f (int): kernel/filter size\n",
        "                n_s (int): stride size\n",
        "                n_p (int): padding size\n",
        "                n_filters (int): number of filters\n",
        "            max_pool (dict): dict with keys 'pool_size', 'n_s'\n",
        "                pool_size (int): max pooling size\n",
        "                n_s (int): max pooling stride\n",
        "\n",
        "    Returns:\n",
        "        conv_params (dict): dict containg keys 'Wl' (filters of layer l), and 'bl' (biases of layer l)\n",
        "    '''\n",
        "\n",
        "    conv_params = {}\n",
        "    n_C = X.shape[-1]\n",
        "\n",
        "    # Loop over architecture specifications in list\n",
        "    for conv_dim in conv_dims:\n",
        "\n",
        "        l = 1\n",
        "        # Create params for only convolutional layers\n",
        "        if conv_dim == 'conv':\n",
        "            n_filters, n_f = conv_dims[conv_dim]['n_filters'], conv_dims[conv_dim]['n_f']\n",
        "            conv_params['W' + str(l)] = np.random.randn(n_filters, n_f, n_f, n_C) * np.sqrt(2 / (n_f * n_f * n_C))\n",
        "            conv_params['b' + str(l)] = np.zeros((n_filters, 1, 1))\n",
        "            n_C = n_filters\n",
        "            l += 1\n",
        "\n",
        "    return conv_params\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def full_forwardprop(X, y, conv_dims, dense_dims, params):\n",
        "    '''\n",
        "    Forward prop for both convolutional and dense sections of the network, assuming ReLU activation\n",
        "\n",
        "    Args:\n",
        "        X ((m, n_H, n_W, n_C)): input matrix\n",
        "        conv_dims (dict): dict containing either 'conv', or 'max_pool' corresponding to a sub-dict\n",
        "            conv (dict): dict with keys 'n_f', 'n_s', 'n_p', 'n_filters'\n",
        "                n_f (int): kernel/filter size\n",
        "                n_s (int): stride size\n",
        "                n_p (int): padding size\n",
        "                n_filters (int): number of filters\n",
        "            max_pool (dict): dict with keys 'pool_size', 'n_s'\n",
        "                pool_size (int): max pooling size\n",
        "                n_s (int): max pooling stride\n",
        "\n",
        "    Returns:\n",
        "        yhat ((1, m)): predictions from forward prop\n",
        "    '''\n",
        "    (conv_params, dense_params) = params\n",
        "    A_prev = X\n",
        "    conv_caches = []\n",
        "    l = 1\n",
        "\n",
        "    # Enumerate through both convolutional and max pooling layers\n",
        "    for dim in conv_dims:\n",
        "\n",
        "      if dim == 'conv':\n",
        "\n",
        "        # Single convolutional layer with ReLU activation\n",
        "        A_next, cache = vectorized_convolution(A_prev,\n",
        "                                    filters=conv_params['W' + str(l)],\n",
        "                                    biases=conv_params['b' + str(l)],\n",
        "                                    n_s=conv_dims[dim]['n_s'],\n",
        "                                    n_p=conv_dims[dim]['n_p'])\n",
        "        l += 1\n",
        "\n",
        "      elif dim == 'max_pool':\n",
        "        A_next, cache = max_pool_vectorized(A_prev, conv_dims[dim]['pool_size'], conv_dims[dim]['n_s'])\n",
        "\n",
        "      conv_caches.append(cache)\n",
        "      A_prev = A_next\n",
        "\n",
        "    # Forward prop through dense layers\n",
        "    cost, yhat, dense_caches = dense_forward_prop(A_prev, y, dense_params)\n",
        "\n",
        "    return cost, yhat, dense_caches, conv_caches, A_next"
      ],
      "metadata": {
        "id": "Xc3qJMeS3Whq"
      },
      "id": "Xc3qJMeS3Whq",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_backprop(yhat, y, dense_caches, conv_caches, conv_dims, A_next):\n",
        "    '''\n",
        "    Backprop for both the dense and convolutional sections of the nework\n",
        "\n",
        "    Args:\n",
        "        yhat ((1, m)): vector of activations of output layer for each example\n",
        "        y ((1, m)): vector of labels for each training example\n",
        "        caches (list): list of each layer's cache dictionary\n",
        "          cache (dict): Python dictionary containing\n",
        "            A_prev ((m, n_H, n_W, n_C)): previous activation matrices\n",
        "            filters ((n_filters, n_f, n_f, n_C)): filters\n",
        "            biases (n_filters, 1): bias term for each filter\n",
        "            stride (int): stride size\n",
        "            padding (int): padding size\n",
        "        conv_dims (dict): dict containing either 'conv', or 'max_pool' corresponding to a sub-dict\n",
        "            conv (dict): dict with keys 'n_f', 'n_s', 'n_p', 'n_filters'\n",
        "                n_f (int): kernel/filter size\n",
        "                n_s (int): stride size\n",
        "                n_p (int): padding size\n",
        "                n_filters (int): number of filters\n",
        "            max_pool (dict): dict with keys 'pool_size', 'n_s'\n",
        "                pool_size (int): max pooling size\n",
        "                n_s (int): max pooling stride\n",
        "\n",
        "    Returns:\n",
        "        dense_grads (dict): dict containg keys 'W + str(l)' and 'b + str(l)\n",
        "        conv_grads (dict): dict containing keys 'W + str(l)' and 'b + str(l)\n",
        "    '''\n",
        "\n",
        "    # Full dense backprop\n",
        "    dense_grads = dense_backprop(yhat, y, dense_caches)\n",
        "\n",
        "    # Get gradient for output of dense section and reshape back to 4D\n",
        "    shape = A_next.shape\n",
        "    dA_next = dense_grads['dA0'].T.reshape(shape)\n",
        "\n",
        "    conv_grads = {}\n",
        "\n",
        "    # Create a mapping from cache index to conv layer number used in params\n",
        "    conv_layer_numbers = []\n",
        "    current_conv_l = 1\n",
        "    for dim_type in conv_dims:\n",
        "\n",
        "      if dim_type == 'conv':\n",
        "        conv_layer_numbers.append(current_conv_l)\n",
        "        current_conv_l += 1\n",
        "      else: # For pooling layers, no conv param number\n",
        "        conv_layer_numbers.append(None)\n",
        "\n",
        "    # Iterate through conv_caches in reverse order for backpropagation\n",
        "    for cache_idx in range(len(conv_caches) - 1, -1, -1):\n",
        "\n",
        "      # Get current cache from caches\n",
        "      conv_cache = conv_caches[cache_idx]\n",
        "      dim_type = list(conv_dims.keys())[cache_idx] # Get the type of layer at this cache index\n",
        "\n",
        "      # Backprop for convolutional layer\n",
        "      if dim_type == 'conv':\n",
        "        conv_layer_num = conv_layer_numbers[cache_idx]\n",
        "        if conv_layer_num is None:\n",
        "          raise ValueError(f\"Mismatch in conv_layer_numbers and cache_idx for conv layer at index {cache_idx}\")\n",
        "\n",
        "        dA_prev, dW, db = vec_conv_back_prop(dA_next, conv_cache)\n",
        "\n",
        "        # Update conv_grads dictionary using the correct 'l' (conv_layer_num)\n",
        "        conv_grads['dW' + str(conv_layer_num)] = dW\n",
        "        conv_grads['db' + str(conv_layer_num)] = db\n",
        "\n",
        "      # Backprop for max pooling layer\n",
        "      elif dim_type == 'max_pool':\n",
        "        A_prev, pool_size, n_s = conv_cache['A_prev'], conv_cache['pool_size'], conv_cache['stride']\n",
        "        dA_prev = vec_max_pool_backprop(dA_next, A_prev, pool_size, n_s)\n",
        "\n",
        "      # Update dA_next\n",
        "      dA_next = dA_prev\n",
        "\n",
        "    # Return gradient dictionaries\n",
        "    return conv_grads, dense_grads"
      ],
      "metadata": {
        "id": "ry4Vr1FtxTAe"
      },
      "id": "ry4Vr1FtxTAe",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Adam(params, grads, S, V, iter, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "    '''\n",
        "    Adam optimization algorithm, combining both RMSprop and gradient descent with momentum, as well as bias correction\n",
        "\n",
        "    Args:\n",
        "      parameters (tuple): tuple of conv_params and dense_params dictionaries\n",
        "        conv_params (dict): dict containg keys 'Wl' (filters of layer l), and 'bl' (biases of layer l)\n",
        "        dense_params (dict): dict with keys 'Wl' (weights of layer l) and 'bl' (biases of layer l)\n",
        "      grads (tuple): tuple of conv_grads and dense_grads dicts\n",
        "        conv_grads (dict): dict with keys 'dWl' and 'dbl' (i.e., the partial derivative of each parameter)\n",
        "        dense_grads (dict): dict with keys 'dWl' and 'dbl' (i.e., the partial derivative of each parameter)\n",
        "      S (tuple): contains exponential moving average of squared gradients dictionaries of conv_S and dense_S\n",
        "      V (tuple): contains exponential moving average of gradients dictionaries of conv_V and dense_V\n",
        "\n",
        "    Returns:\n",
        "      parameters (tuple): updated tuple of conv_params and dense_params dictionaries\n",
        "        conv_params (dict): updated dict containg keys 'Wl' (filters of layer l), and 'bl' (biases of layer l)\n",
        "        dense_params (dict): updated dict with keys 'Wl' (weights of layer l) and 'bl' (biases of layer l)\n",
        "      S (tuple): contains exponential moving average of squared gradients dictionaries of conv_S and dense_S\n",
        "      V (tuple): contains exponential moving average of gradients dictionaries of conv_V and dense_V\n",
        "    '''\n",
        "\n",
        "    # Unpack tuples\n",
        "    (conv_params, dense_params) = params\n",
        "    (conv_grads, dense_grads) = grads\n",
        "    (conv_S, dense_S) = S\n",
        "    (conv_V, dense_V) = V\n",
        "\n",
        "    # Iterate over all dense_params\n",
        "    L = len(dense_params)//2\n",
        "    for l in range(1, L+1):\n",
        "\n",
        "        # Get gradients\n",
        "        dWl, dbl = dense_grads['dW'+str(l)], dense_grads['db'+str(l)]\n",
        "\n",
        "        # Update velocity terms\n",
        "        dense_V['dW'+str(l)] = (beta1 * dense_V['dW'+str(l)]) + ((1-beta1) * dWl)\n",
        "        dense_V['db'+str(l)] = (beta1 * dense_V['db'+str(l)]) + ((1-beta1) * dbl)\n",
        "\n",
        "        # Update squared-gradient terms\n",
        "        dense_S['dW' + str(l)] = (beta2 * dense_S['dW' + str(l)]) + ((1 - beta2) * np.square(dWl))\n",
        "        dense_S['db' + str(l)] = (beta2 * dense_S['db' + str(l)]) + ((1 - beta2) * np.square(dbl))\n",
        "\n",
        "        # Bias correction\n",
        "        vdW_corrected = dense_V['dW'+str(l)] / (1 - (beta1 ** iter))\n",
        "        vdb_corrected = dense_V['db'+str(l)] / (1 - (beta1 ** iter))\n",
        "\n",
        "        sdW_corrected = dense_S['dW' + str(l)] / (1 - (beta2 ** iter))\n",
        "        sdb_corrected = dense_S['db' + str(l)] / (1 - (beta2 ** iter))\n",
        "\n",
        "        # Update Parameters\n",
        "        dense_params['W'+str(l)] -= (alpha * vdW_corrected) / (np.sqrt(sdW_corrected)+epsilon)\n",
        "        dense_params['b'+str(l)] -= (alpha * vdb_corrected) / (np.sqrt(sdb_corrected)+epsilon)\n",
        "\n",
        "  # Iterate over all conv_params\n",
        "    L = len(conv_params)//2\n",
        "    for l in range(1, L+1):\n",
        "\n",
        "        # Get gradients\n",
        "        dWl, dbl = conv_grads['dW'+str(l)], conv_grads['db'+str(l)]\n",
        "\n",
        "        # Update velocity terms\n",
        "        conv_V['dW'+str(l)] = (beta1 * conv_V['dW'+str(l)]) + ((1-beta1) * dWl)\n",
        "        conv_V['db'+str(l)] = (beta1 * conv_V['db'+str(l)]) + ((1-beta1) * dbl)\n",
        "\n",
        "        # Update squared-gradient terms\n",
        "        conv_S['dW' + str(l)] = (beta2 * conv_S['dW' + str(l)]) + ((1 - beta2) * np.square(dWl))\n",
        "        conv_S['db' + str(l)] = (beta2 * conv_S['db' + str(l)]) + ((1 - beta2) * np.square(dbl))\n",
        "\n",
        "        # Bias correction\n",
        "        vdW_corrected = conv_V['dW'+str(l)] / (1 - (beta1 ** iter))\n",
        "        vdb_corrected = conv_V['db'+str(l)] / (1 - (beta1 ** iter))\n",
        "\n",
        "        sdW_corrected = conv_S['dW' + str(l)] / (1 - (beta2 ** iter))\n",
        "        sdb_corrected = conv_S['db' + str(l)] / (1 - (beta2 ** iter))\n",
        "\n",
        "        # Update Parameters\n",
        "        conv_params['W'+str(l)] -= (alpha * vdW_corrected) / (np.sqrt(sdW_corrected)+epsilon)\n",
        "        conv_params['b'+str(l)] -= (alpha * vdb_corrected) / (np.sqrt(sdb_corrected)+epsilon)\n",
        "\n",
        "    # Repack tuples\n",
        "    params = (conv_params, dense_params)\n",
        "    S = (conv_S, dense_S)\n",
        "    V = (conv_V, dense_V)\n",
        "\n",
        "    return params, S, V"
      ],
      "metadata": {
        "id": "gsrck3Sws9iv"
      },
      "id": "gsrck3Sws9iv",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_adam(params):\n",
        "\n",
        "  # Initialize adam\n",
        "  (conv_params, dense_params) = params\n",
        "  dense_S, conv_S, dense_V, conv_V = {}, {}, {}, {}\n",
        "  S, V = (conv_S, dense_S), (conv_V, dense_V)\n",
        "\n",
        "  # Loop over dense params\n",
        "  L = len(dense_params)//2\n",
        "  for l in range(1, L+1):\n",
        "\n",
        "    # RMS prop terms\n",
        "    dense_S['dW'+str(l)] = np.zeros_like(dense_params['W'+str(l)])\n",
        "    dense_S['db'+str(l)] = np.zeros_like(dense_params['b'+str(l)])\n",
        "\n",
        "    # Momentum terms\n",
        "    dense_V['dW'+str(l)] = np.zeros_like(dense_params['W'+str(l)])\n",
        "    dense_V['db'+str(l)] = np.zeros_like(dense_params['b'+str(l)])\n",
        "\n",
        "  L = len(conv_params)//2\n",
        "  for l in range(1, L+1):\n",
        "    # RMS prop terms\n",
        "    conv_S['dW'+str(l)] = np.zeros_like(conv_params['W'+str(l)])\n",
        "    conv_S['db'+str(l)] = np.zeros_like(conv_params['b'+str(l)])\n",
        "\n",
        "    # Momentum terms\n",
        "    conv_V['dW'+str(l)] = np.zeros_like(conv_params['W'+str(l)])\n",
        "    conv_V['db'+str(l)] = np.zeros_like(conv_params['b'+str(l)])\n",
        "\n",
        "  S, V = (conv_S, dense_S), (conv_V, dense_V)\n",
        "\n",
        "  return S, V\n",
        "\n"
      ],
      "metadata": {
        "id": "0xL_V05r0xNJ"
      },
      "id": "0xL_V05r0xNJ",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, X_test, y_test, dims, epochs=10):\n",
        "    '''\n",
        "    Forward and backprop to train CNN model\n",
        "\n",
        "    Args:\n",
        "        X ((m, n_H, n_W, n_C)): inputs\n",
        "    '''\n",
        "    # Extract network architecture\n",
        "    (conv_dims, dense_dims) = dims\n",
        "\n",
        "    # Initialize parameters\n",
        "    conv_params = initialize_convolution(X, conv_dims)\n",
        "    dense_params = initialize_parameters(X, dense_dims, conv_params, conv_dims)\n",
        "    params = (conv_params, dense_params)\n",
        "\n",
        "    # Initialize Adam's momentum and RMSprop terms once before training loop\n",
        "    S, V = initialize_adam(params)\n",
        "\n",
        "    # Empty list to record cost\n",
        "    cost_history_train = []\n",
        "    cost_history_test = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "      # Full forward prop\n",
        "      cost, yhat, dense_caches, conv_caches, A_next = full_forwardprop(X, y, conv_dims, dense_dims, params)\n",
        "      cost_history_train.append(cost)\n",
        "      _, yhat_test, _, _, _ = full_forwardprop(X_test, y_test, conv_dims, dense_dims, params)\n",
        "      cost_test = binary_cross_entropy_cost(yhat_test, y_test)\n",
        "      cost_history_test.append(cost_test)\n",
        "\n",
        "      # Full backprop\n",
        "      conv_grads, dense_grads = full_backprop(yhat, y, dense_caches, conv_caches, conv_dims, A_next)\n",
        "      grads = (conv_grads, dense_grads)\n",
        "\n",
        "      # Adam optimization algorithm\n",
        "      params, S, V = Adam(params, grads, S, V, epoch)\n",
        "\n",
        "    cost_history = (cost_history_train, cost_history_test)\n",
        "\n",
        "    return params, cost_history"
      ],
      "metadata": {
        "id": "a_aDEG4mypSg"
      },
      "id": "a_aDEG4mypSg",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, y, params, dims):\n",
        "  '''\n",
        "  Forward prop to output predictions after training\n",
        "\n",
        "  Args:\n",
        "      X ((m, n_H, n_W, n_C)): inputs\n",
        "      y ((m, 1)): outputs\n",
        "  '''\n",
        "\n",
        "  # Initialize network\n",
        "  A_prev = X\n",
        "  conv_caches = []\n",
        "  l = 1\n",
        "\n",
        "  # Extract network architecture\n",
        "  (conv_dims, dense_dims) = dims\n",
        "\n",
        "  # Inference\n",
        "  _, yhat_raw, _, _, A_next = full_forwardprop(X, y, conv_dims, dense_dims, params)\n",
        "\n",
        "  return (yhat_raw > 0.5), yhat_raw\n"
      ],
      "metadata": {
        "id": "mo-NZiXpOiyS"
      },
      "id": "mo-NZiXpOiyS",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load data\n",
        "(train_X, train_y), (test_X, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Select classes 0 and 1 for binary classification\n",
        "mask = (train_y == 0) | (train_y == 1)\n",
        "train_X, train_y = train_X[mask.flatten()], train_y[mask]\n",
        "\n",
        "# Reshape X to (m, n_H, n_W, n_C)\n",
        "train_X = train_X.reshape(train_X.shape[0], 28, 28, 1)\n",
        "test_X = test_X.reshape(test_X.shape[0], 28, 28, 1)\n",
        "\n",
        "# Reshape y to (1, m)\n",
        "train_y = train_y.reshape(1, train_y.shape[0])\n",
        "test_y = test_y.reshape(1, test_y.shape[0])\n",
        "\n",
        "# Normalization\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0"
      ],
      "metadata": {
        "id": "XADEVct3wUgy"
      },
      "id": "XADEVct3wUgy",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "id": "w1GzzqClHtB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f37836b-5dd4-491c-ceed-e650ed5237a9"
      },
      "id": "w1GzzqClHtB3",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12665, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify conv net architecture\n",
        "conv_1 = {'n_f' : 3, 'n_s' : 1, 'n_p' : 0, 'n_filters' : 8}\n",
        "pool_1 = {'pool_size' : 2, 'n_s' : 2}\n",
        "conv_dims = {'conv' : conv_1, 'max_pool' : pool_1}\n",
        "\n",
        "# Specify dense network architecture\n",
        "dense_dims = [64, 1]\n",
        "\n",
        "# Overall network architecture\n",
        "dims = (conv_dims, dense_dims)\n",
        "\n",
        "# Train network\n",
        "params, cost_history = train(train_X[:1000, :, :, :], train_y[:, :1000], test_X, test_y, dims, epochs=1000)\n"
      ],
      "metadata": {
        "id": "njacxGZ731pl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0a01296edeb444ca8bc8288fd746894e",
            "6126a5b862834baf9c00ba9d848c9ef8",
            "6519c56a279742b69e6d2ad53073de7b",
            "07a4d050fb484fc88e0edd36eb8f7e97",
            "ccd6cf1b4dd746e6bff6dc8c63a02184",
            "68ab77d920f94543ae9afc7f0f86d57b",
            "f8d14cc3214e4d8692de34e0dde35bcb",
            "235a54b5fb3a4446a033d607dd538ea6",
            "ec3bd036049a4155a7f79d95df7a6b6e",
            "30e9c6803d614e619c3fcde3290f35f2",
            "1d10d9d5f778424c8fbe2dab2ca8ad78"
          ]
        },
        "outputId": "c985d594-d103-4f8b-9e3e-27a093f9be92"
      },
      "id": "njacxGZ731pl",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a01296edeb444ca8bc8288fd746894e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cost_history[0], color='orange')\n",
        "plt.plot(cost_history[1], color='deepskyblue')\n",
        "plt.title('Training and Test Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "w5Ry9ShxIdZ9",
        "outputId": "056ae1d7-4a06-4ace-cae7-312617249cc5"
      },
      "id": "w5Ry9ShxIdZ9",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process for binary classification\n",
        "mask = (test_y == 0) | (test_y == 1)\n",
        "test_X, test_y = test_X[mask.flatten()], test_y[mask]\n",
        "\n",
        "# Reshape y to (1, m)\n",
        "test_y = test_y.reshape(1, test_y.shape[0])\n",
        "\n",
        "\n",
        "# Inference\n",
        "y_pred_binary, y_pred_raw = predict(test_X, test_y, params, dims)\n",
        "\n",
        "# Model evaluation\n",
        "print(f'Model accuracy: {accuracy_score(y_pred=y_pred_binary, y_true=test_y)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL_xV2i2ONPW",
        "outputId": "4f0181bf-2caf-41cc-f0d2-eacf808b38f3"
      },
      "id": "oL_xV2i2ONPW",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "jkIJ6R9XCKTl",
        "outputId": "854dc13e-71d4-4f6d-f000-9694d0d3f757"
      },
      "id": "jkIJ6R9XCKTl",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cost' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1330154178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cost' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a01296edeb444ca8bc8288fd746894e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6126a5b862834baf9c00ba9d848c9ef8",
              "IPY_MODEL_6519c56a279742b69e6d2ad53073de7b",
              "IPY_MODEL_07a4d050fb484fc88e0edd36eb8f7e97"
            ],
            "layout": "IPY_MODEL_ccd6cf1b4dd746e6bff6dc8c63a02184"
          }
        },
        "6126a5b862834baf9c00ba9d848c9ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ab77d920f94543ae9afc7f0f86d57b",
            "placeholder": "",
            "style": "IPY_MODEL_f8d14cc3214e4d8692de34e0dde35bcb",
            "value": "100%"
          }
        },
        "6519c56a279742b69e6d2ad53073de7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235a54b5fb3a4446a033d607dd538ea6",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec3bd036049a4155a7f79d95df7a6b6e",
            "value": 1000
          }
        },
        "07a4d050fb484fc88e0edd36eb8f7e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e9c6803d614e619c3fcde3290f35f2",
            "placeholder": "",
            "style": "IPY_MODEL_1d10d9d5f778424c8fbe2dab2ca8ad78",
            "value": "1000/1000[1:39:28&lt;00:00,5.78s/it]"
          }
        },
        "ccd6cf1b4dd746e6bff6dc8c63a02184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ab77d920f94543ae9afc7f0f86d57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d14cc3214e4d8692de34e0dde35bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "235a54b5fb3a4446a033d607dd538ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3bd036049a4155a7f79d95df7a6b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30e9c6803d614e619c3fcde3290f35f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d10d9d5f778424c8fbe2dab2ca8ad78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}