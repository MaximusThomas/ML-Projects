{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "XCgpaUX6H7cd",
      "metadata": {
        "id": "XCgpaUX6H7cd"
      },
      "source": [
        "# Convolutional neural network from scratch\n",
        "\n",
        "Binary classification CNN using just NumPy, linear algebra, and calculus with no PyTorch or TensorFlow.\n",
        "\n",
        "Fully vectorized to ensure efficient inference and training.\n",
        "\n",
        "[GitHub repo](https://github.com/MaximusThomas/ML-Projects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "79a86001",
      "metadata": {
        "id": "79a86001"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "5470f024",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "ApFvTuVRKGsO",
      "metadata": {
        "id": "ApFvTuVRKGsO"
      },
      "outputs": [],
      "source": [
        "mem_pool = {}\n",
        "def get_buffer(name, shape, dtype=np.float32):\n",
        "\n",
        "    key = (name, shape)\n",
        "    if key not in mem_pool:\n",
        "        mem_pool[key] = np.zeros(shape, dtype=dtype)\n",
        "    else:\n",
        "        mem_pool[key].fill(0)\n",
        "    return mem_pool[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "oYwxSO2G7g2b",
      "metadata": {
        "id": "oYwxSO2G7g2b"
      },
      "outputs": [],
      "source": [
        "def vectorized_convolution(A_prev, filters, biases, n_s, n_p):\n",
        "    '''\n",
        "    Single convolutional layer of all filters, assuming ReLU activation\n",
        "\n",
        "    Args:\n",
        "        A_prev ((m, n_H, n_W, n_C)): matrix of activations\n",
        "        filters ((n_filters, n_f, n_f, n_C)): filters\n",
        "        biases (n_filters): bias term for each filter\n",
        "        n_s (int): convolution stride\n",
        "        n_p (int): amount of padding (assumes square symmetrical)\n",
        "\n",
        "    Returns:\n",
        "        A_next ((m, n_H_, n_W_, n_filters)): output matrix of activations\n",
        "        cache (dict): Python dictionary containing keys \"A_prev\", \"A_next\", \"filters\", \"biases\", \"stride\", \"padding\", \"Z\"\n",
        "    '''\n",
        "    # Get filter shape and activation height and width\n",
        "    n_f, n_filters = filters.shape[1], filters.shape[0]\n",
        "    (m, n_H, n_W, n_C) = A_prev.shape\n",
        "\n",
        "    # Calculate output height and width\n",
        "    n_H_ = int(np.floor((n_H + (2 * n_p) - n_f) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W + (2 * n_p) - n_f) / n_s)) + 1\n",
        "\n",
        "    padded_shape = (m, n_H + (2 * n_p), n_W + (2 * n_p), n_C)\n",
        "    A_prev_pad = get_buffer(\"conv_fwd_pad\", padded_shape, A_prev.dtype)\n",
        "    A_prev_pad[:, n_p:n_p+n_H, n_p:n_p+n_W, :] = A_prev\n",
        "\n",
        "    # Create view of sliding windows\n",
        "    shape = (m, n_H_, n_W_, n_f, n_f, n_C)\n",
        "    strides = (A_prev_pad.strides[0], n_s * A_prev_pad.strides[1], n_s * A_prev_pad.strides[2],\n",
        "               A_prev_pad.strides[1], A_prev_pad.strides[2], A_prev_pad.strides[3])\n",
        "    windows = np.lib.stride_tricks.as_strided(A_prev_pad, shape=shape, strides=strides)\n",
        "\n",
        "    # 'mhwfgc' = batch, height, width, filter_h, filter_w, channels\n",
        "    # 'dfgc' = n_filters, filter_h, filter_w, channels\n",
        "    Z_reshaped = np.einsum('mhwfgc,dfgc->mhwd', windows, filters) + biases\n",
        "\n",
        "    # ReLU activation function\n",
        "    A_next = np.maximum(Z_reshaped, 0)\n",
        "\n",
        "    # Cache important values for backprop\n",
        "    cache = {\n",
        "        'A_prev': A_prev, 'filters': filters, 'biases': biases,\n",
        "        'stride': n_s, 'padding': n_p, 'windows': windows, 'Z': Z_reshaped\n",
        "    }\n",
        "\n",
        "    return A_next, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "k5V90cxLAwEk",
      "metadata": {
        "id": "k5V90cxLAwEk"
      },
      "outputs": [],
      "source": [
        "def max_pool_vectorized(A_prev, pool_size, n_s):\n",
        "    '''\n",
        "    Max pooling step across all examples and filters\n",
        "\n",
        "    Args:\n",
        "        A_prev ((m, n_H, n_W, n_C)): matrix of activations\n",
        "        pool_size (int): size of pool, assuming square\n",
        "        n_s (int): stride\n",
        "\n",
        "    Returns:\n",
        "        A_next ((m, n_H_, n_W_, n_filters)): pooled output matrix of activations\n",
        "        cache (dict): Python dictionary containing keys \"A_prev\", \"pool_size\", \"stride\"\n",
        "    '''\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    (m, n_H, n_W, n_C) = A_prev.shape\n",
        "    n_H_ = int(np.floor((n_H - pool_size) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W - pool_size) / n_s)) + 1\n",
        "\n",
        "    # Cache values for backprop\n",
        "    cache = {}\n",
        "    cache['A_prev'], cache['pool_size'], cache['stride'] = A_prev, pool_size, n_s\n",
        "\n",
        "    # Create windows\n",
        "    shape = (m, n_H_, n_W_, pool_size, pool_size, n_C)\n",
        "    strides = (A_prev.strides[0],\n",
        "               n_s * A_prev.strides[1],\n",
        "               n_s * A_prev.strides[2],\n",
        "               A_prev.strides[1],\n",
        "               A_prev.strides[2],\n",
        "               A_prev.strides[3])\n",
        "\n",
        "    windows = np.lib.stride_tricks.as_strided(A_prev, shape, strides)\n",
        "\n",
        "    # Take max over each max pooling position\n",
        "    A_next = np.max(windows.reshape(m, n_H_, n_W_, pool_size * pool_size, n_C), axis=3)\n",
        "\n",
        "    return A_next, cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "N2f4qPSBCpSJ",
      "metadata": {
        "id": "N2f4qPSBCpSJ"
      },
      "outputs": [],
      "source": [
        "def vec_conv_back_prop(dA_next, cache):\n",
        "    '''\n",
        "    Back prop for a single convolution layer\n",
        "\n",
        "    Args:\n",
        "        dA ((m, n_H_, n_W_, n_filters)): gradient of ReLU activations\n",
        "        cache (): cache of A_prev, filters (weights), stride, and padding\n",
        "    '''\n",
        "\n",
        "    # Retrieve cached values\n",
        "    W, n_s, n_p, Z, windows, A_prev = (\n",
        "        cache['filters'], cache['stride'], cache['padding'],\n",
        "        cache['Z'], cache['windows'], cache['A_prev']\n",
        "    )\n",
        "\n",
        "    n_f = W.shape[1]\n",
        "\n",
        "    # Differentiate ReLU\n",
        "    dZ = dA_next * (Z > 0)\n",
        "\n",
        "    # Optimization with np.einsum\n",
        "    dW = np.einsum('mhwd,mhwfgc->dfgc', dZ, windows)\n",
        "    db = np.sum(dZ, axis=(0, 1, 2), keepdims=True)\n",
        "\n",
        "    # Get d_windows (m, n_H_out, n_W_out, n_f, n_f, n_C)\n",
        "    d_windows = np.einsum('mhwd,dfgc->mhwfgc', dZ, W)\n",
        "\n",
        "    # col2im using pre-allocation and slicing\n",
        "    (m, n_H_A, n_W_A, n_C_A) = A_prev.shape\n",
        "    pad_shape = (m, n_H_A + (2 * n_p), n_W_A + (2 * n_p), n_C_A)\n",
        "    dA_prev_pad = get_buffer(\"conv_back_pad\", pad_shape, A_prev.dtype)\n",
        "\n",
        "    for i in range(n_f):\n",
        "        for j in range(n_f):\n",
        "            dA_prev_pad[:, i:i+d_windows.shape[1]*n_s:n_s, j:j+d_windows.shape[2]*n_s:n_s, :] += \\\n",
        "                d_windows[:, :, :, i, j, :]\n",
        "\n",
        "    # Remove padding\n",
        "    if n_p > 0:\n",
        "        dA_prev = dA_prev_pad[:, n_p:n_H_A+n_p, n_p:n_W_A+n_p, :].copy()\n",
        "    else:\n",
        "        dA_prev = dA_prev_pad\n",
        "\n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "9LwrHPFwDHZ4",
      "metadata": {
        "id": "9LwrHPFwDHZ4"
      },
      "outputs": [],
      "source": [
        "def vec_max_pool_backprop(dA_next, A_prev, pool_size, n_s):\n",
        "  '''\n",
        "  Backprop for a max pooling layer\n",
        "\n",
        "  Args:\n",
        "      dA_next ((m, n_H_, n_W_, n_filters)): tensor of activations from max pooling layer\n",
        "      pool_size (int): size of pool, assuming square\n",
        "      n_s (int): stride\n",
        "\n",
        "  Returns:\n",
        "      dA_prev ((m, n_H, n_W, n_C)): tensor of activations from previous conv layer\n",
        "  '''\n",
        "\n",
        "  # Retrieve shapes\n",
        "  # dA_next is (m, n_H_out, n_W_out, n_C) from full_backprop after reshape\n",
        "  (m, n_H_out, n_W_out, n_C) = dA_next.shape\n",
        "  (m_A_prev, n_H_A_prev, n_W_A_prev, n_C_A_prev) = A_prev.shape\n",
        "\n",
        "  # Calculate output dimensions for pooling based on A_prev\n",
        "  n_H_pool = int(np.floor((n_H_A_prev - pool_size) / n_s)) + 1\n",
        "  n_W_pool = int(np.floor((n_W_A_prev - pool_size) / n_s)) + 1\n",
        "\n",
        "  # Create windows view on A_prev for mask generation\n",
        "  shape_windows = (m_A_prev, n_H_pool, n_W_pool, pool_size, pool_size, n_C_A_prev)\n",
        "  strides_windows = (A_prev.strides[0],\n",
        "                     n_s * A_prev.strides[1],\n",
        "                     n_s * A_prev.strides[2],\n",
        "                     A_prev.strides[1],\n",
        "                     A_prev.strides[2],\n",
        "                     A_prev.strides[3])\n",
        "  windows = np.lib.stride_tricks.as_strided(A_prev, shape=shape_windows, strides=strides_windows)\n",
        "\n",
        "  # Create mask for max values (indices where max was taken in forward pass)\n",
        "  A_prev_flat = windows.reshape(m_A_prev, n_H_pool, n_W_pool, pool_size * pool_size, n_C_A_prev)\n",
        "  arg_max = np.argmax(A_prev_flat, axis=3)\n",
        "  mask = np.zeros_like(A_prev_flat)\n",
        "\n",
        "  # Indexing to set only the first max occurrence to 1\n",
        "  m_idx, h_idx, w_idx, c_idx = np.indices((m_A_prev, n_H_pool, n_W_pool, n_C_A_prev))\n",
        "  mask[m_idx, h_idx, w_idx, arg_max, c_idx] = 1\n",
        "\n",
        "  # Reshape dA_next for broadcasting with mask\n",
        "  dA_next_reshaped_for_mask = dA_next[:, :, :, np.newaxis, :] # (m, n_H_out, n_W_out, 1, n_C)\n",
        "\n",
        "  # Apply mask to distribute gradients only to the maximum elements\n",
        "  dA_col_flat = mask * dA_next_reshaped_for_mask # (m, n_H_pool, n_W_pool, pool_size*pool_size, n_C)\n",
        "  dA_col = dA_col_flat.reshape(m_A_prev, n_H_pool, n_W_pool, pool_size, pool_size, n_C_A_prev) # (m, n_H_pool, n_W_pool, pool_size, pool_size, n_C)\n",
        "\n",
        "  # col2im: Initialize dA_prev with zeros, then accumulate gradients\n",
        "  dA_prev = np.zeros_like(A_prev)\n",
        "  for i in range(pool_size):\n",
        "      for j in range(pool_size):\n",
        "          dA_prev[:, i:i+n_H_pool*n_s:n_s, j:j+n_W_pool*n_s:n_s, :] += dA_col[:, :, :, i, j, :]\n",
        "\n",
        "  return dA_prev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "7d6641d9",
      "metadata": {
        "id": "7d6641d9"
      },
      "outputs": [],
      "source": [
        "def softmax(Z):\n",
        "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "7c6b8cf4",
      "metadata": {
        "id": "7c6b8cf4"
      },
      "outputs": [],
      "source": [
        "def categorical_cross_entropy_cost(A, Y, epsilon=1e-8):\n",
        "\n",
        "    m = Y.shape[1]\n",
        "    A = np.clip(A, epsilon, 1 - epsilon)\n",
        "    cost = -1/m * np.sum(Y * np.log(A))\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "8723fdb9",
      "metadata": {
        "id": "8723fdb9"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(X, dense_dims, conv_params, conv_dims):\n",
        "\n",
        "    m = X.shape[0]\n",
        "    A_prev = X\n",
        "    l = 1\n",
        "    for dim in conv_dims:\n",
        "\n",
        "      if dim == 'conv' or 'conv' in dim:\n",
        "\n",
        "        # Single convolutional layer with ReLU activation\n",
        "        A_next, _ = vectorized_convolution(A_prev,\n",
        "                                    filters=conv_params['W' + str(l)],\n",
        "                                    biases=conv_params['b' + str(l)],\n",
        "                                    n_s=conv_dims[dim]['n_s'],\n",
        "                                    n_p=conv_dims[dim]['n_p'])\n",
        "        l += 1\n",
        "\n",
        "      elif dim == 'max_pool' or 'pool' in dim:\n",
        "        A_next, _ = max_pool_vectorized(A_prev, conv_dims[dim]['pool_size'], conv_dims[dim]['n_s'])\n",
        "\n",
        "      A_prev = A_next\n",
        "\n",
        "    dense_dims_local = dense_dims.copy()\n",
        "    dense_dims_local.insert(0, A_prev.reshape(m, -1).shape[1])\n",
        "\n",
        "    parameters = {}\n",
        "    for l in range(1, len(dense_dims_local)):\n",
        "        parameters['W' + str(l)] = np.random.randn(dense_dims_local[l], dense_dims_local[l - 1]).astype(np.float32) * np.sqrt(2/dense_dims_local[l-1]).astype(np.float32)\n",
        "        parameters['b' + str(l)] = np.zeros((dense_dims_local[l], 1)).astype(np.float32)\n",
        "\n",
        "    return parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "5819464c",
      "metadata": {
        "id": "5819464c"
      },
      "outputs": [],
      "source": [
        "def dense_forward_prop(conv_prev, y, parameters):\n",
        "    '''\n",
        "    Forward prop for dense layers, flattening convolutional output, assuming ReLU activation and sigmoid output activation\n",
        "\n",
        "    Args:\n",
        "        conv_prev ((m, n_H, n_W, n_filters)): tensor of activations from final max pooling layer\n",
        "        parameters (dict): dictionary containing all dense network parameters\n",
        "            W ((n_l, n_l_prev)): matrix of weights\n",
        "            b ((n_l, 1)): column vector of bias terms\n",
        "        y ((1, m)): labels\n",
        "\n",
        "    Returns:\n",
        "        yhat ((1, m)): predictions from forward prop\n",
        "    '''\n",
        "\n",
        "    # Flatten A_prev into a 2D matrix (Features x Batch)\n",
        "    m = conv_prev.shape[0]\n",
        "    A_prev = conv_prev.reshape(m, -1).T\n",
        "\n",
        "    # Forward prop through dense network\n",
        "    caches = []\n",
        "    L = len(parameters) // 2\n",
        "    for l in range(1, L):\n",
        "        cache = {}\n",
        "\n",
        "        # Calculate linear product\n",
        "        Z = np.dot(parameters['W' + str(l)], A_prev) + parameters['b' + str(l)]\n",
        "        cache['Z' + str(l)] = Z\n",
        "        cache['W' + str(l)] = parameters['W' + str(l)]\n",
        "\n",
        "        # Apply activation function\n",
        "        A_next = np.maximum(Z, 0)\n",
        "        cache['A' + str(l-1)] = A_prev\n",
        "        A_prev = A_next\n",
        "\n",
        "        # Append cache\n",
        "        caches.append(cache)\n",
        "\n",
        "    # Output layer\n",
        "    cache = {}\n",
        "    cache['A' + str(L-1)] = A_prev\n",
        "    Z = np.dot(parameters['W' + str(L)], A_prev) + parameters['b' + str(L)]\n",
        "    cache['Z' + str(L)] = Z\n",
        "    cache['W' + str(L)] = parameters['W' + str(L)]\n",
        "    caches.append(cache)\n",
        "    yhat = softmax(Z)\n",
        "\n",
        "    # Calculate loss\n",
        "    cost = categorical_cross_entropy_cost(yhat, y)\n",
        "\n",
        "    return cost, yhat, caches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "cc2415a6",
      "metadata": {
        "id": "cc2415a6"
      },
      "outputs": [],
      "source": [
        "def dense_backprop(yhat, y, caches):\n",
        "    '''\n",
        "    Backprop for dense layers, assuming ReLU activation and sigmoid output activation\n",
        "\n",
        "    Args:\n",
        "        yhat ((1, m)): vector of activations of output layer for each example\n",
        "        y ((1, m)): vector of labels for each training example\n",
        "        caches (list): list of each layer's cache dictionary\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    '''\n",
        "\n",
        "    m = yhat.shape[1]\n",
        "    grads = {}\n",
        "    L = len(caches)\n",
        "\n",
        "    # Backprop for output layer\n",
        "    cache = caches[-1]\n",
        "    grads['dZ' + str(L)] = yhat - y\n",
        "    grads['dW' + str(L)] = 1/m * np.dot(grads['dZ' + str(L)], cache['A' + str(L-1)].T)\n",
        "    grads['db' + str(L)] = 1/m * np.sum(grads['dZ' + str(L)], axis=1, keepdims=True)\n",
        "    grads['dA' + str(L-1)] = np.dot(cache['W' + str(L)].T, grads['dZ' + str(L)])\n",
        "\n",
        "    # Backprop for hidden layers\n",
        "    for l in range(L-1, 0, -1):\n",
        "\n",
        "      cache = caches[l-1]\n",
        "      dZ = np.array(grads['dA' + str(l)], copy=True)\n",
        "      dZ[cache['Z' + str(l)] <= 0] = 0\n",
        "      grads['dZ' + str(l)] = dZ\n",
        "\n",
        "      grads['dW' + str(l)] = 1/m * np.dot(grads['dZ' + str(l)], cache['A' + str(l-1)].T)\n",
        "      grads['db' + str(l)] = 1/m * np.sum(grads['dZ' + str(l)], axis=1, keepdims=True)\n",
        "      grads['dA' + str(l-1)] = np.dot(cache['W' + str(l)].T, grads['dZ' + str(l)])\n",
        "\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "c84f820f",
      "metadata": {
        "id": "c84f820f"
      },
      "outputs": [],
      "source": [
        "def initialize_convolution(X, conv_dims):\n",
        "    '''\n",
        "    Initializes parameters for convolutional part of network\n",
        "\n",
        "    Args:\n",
        "        X (((m, n_H, n_W, n_C)): input matrix\n",
        "        conv_dims (dict): dict containing either 'conv', or 'max_pool' corresponding to a sub-dict\n",
        "            conv (dict): dict with keys 'n_f', 'n_s', 'n_p', 'n_filters'\n",
        "                n_f (int): kernel/filter size\n",
        "                n_s (int): stride size\n",
        "                n_p (int): padding size\n",
        "                n_filters (int): number of filters\n",
        "            max_pool (dict): dict with keys 'pool_size', 'n_s'\n",
        "                pool_size (int): max pooling size\n",
        "                n_s (int): max pooling stride\n",
        "\n",
        "    Returns:\n",
        "        conv_params (dict): dict containg keys 'Wl' (filters of layer l), and 'bl' (biases of layer l)\n",
        "    '''\n",
        "\n",
        "    conv_params = {}\n",
        "    n_C = X.shape[-1]\n",
        "    l = 1\n",
        "\n",
        "    for conv_dim in conv_dims:\n",
        "        if conv_dim == 'conv' or 'conv' in conv_dim:\n",
        "            n_filters, n_f = conv_dims[conv_dim]['n_filters'], conv_dims[conv_dim]['n_f']\n",
        "            conv_params['W' + str(l)] = np.random.randn(n_filters, n_f, n_f, n_C) * np.sqrt(2.0 / (n_f * n_f * n_C))\n",
        "            conv_params['b' + str(l)] = np.zeros((1, 1, 1, n_filters)).astype(np.float32)\n",
        "            n_C = n_filters\n",
        "            l += 1\n",
        "    return conv_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "Xc3qJMeS3Whq",
      "metadata": {
        "id": "Xc3qJMeS3Whq"
      },
      "outputs": [],
      "source": [
        "def full_forwardprop(X, y, conv_dims, dense_dims, params):\n",
        "    '''\n",
        "    Forward prop for both convolutional and dense sections of the network, assuming ReLU activation\n",
        "\n",
        "    Args:\n",
        "        X ((m, n_H, n_W, n_C)): input matrix\n",
        "        conv_dims (dict): dict containing either 'conv', or 'max_pool' corresponding to a sub-dict\n",
        "            conv (dict): dict with keys 'n_f', 'n_s', 'n_p', 'n_filters'\n",
        "                n_f (int): kernel/filter size\n",
        "                n_s (int): stride size\n",
        "                n_p (int): padding size\n",
        "                n_filters (int): number of filters\n",
        "            max_pool (dict): dict with keys 'pool_size', 'n_s'\n",
        "                pool_size (int): max pooling size\n",
        "                n_s (int): max pooling stride\n",
        "\n",
        "    Returns:\n",
        "        yhat ((1, m)): predictions from forward prop\n",
        "    '''\n",
        "    (conv_params, dense_params) = params\n",
        "    A_prev = X\n",
        "    conv_caches = []\n",
        "    l = 1\n",
        "\n",
        "    # Enumerate through both convolutional and max pooling layers\n",
        "    for dim in conv_dims:\n",
        "\n",
        "      if dim == 'conv' or 'conv' in dim:\n",
        "\n",
        "        # Single convolutional layer with ReLU activation\n",
        "        A_next, cache = vectorized_convolution(A_prev,\n",
        "                                    filters=conv_params['W' + str(l)],\n",
        "                                    biases=conv_params['b' + str(l)],\n",
        "                                    n_s=conv_dims[dim]['n_s'],\n",
        "                                    n_p=conv_dims[dim]['n_p'])\n",
        "        l += 1\n",
        "\n",
        "      elif dim == 'max_pool' or 'pool' in dim:\n",
        "        A_next, cache = max_pool_vectorized(A_prev, conv_dims[dim]['pool_size'], conv_dims[dim]['n_s'])\n",
        "\n",
        "      conv_caches.append(cache)\n",
        "      A_prev = A_next\n",
        "\n",
        "    # Forward prop through dense layers\n",
        "    cost, yhat, dense_caches = dense_forward_prop(A_prev, y, dense_params)\n",
        "\n",
        "    return cost, yhat, dense_caches, conv_caches, A_next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "ry4Vr1FtxTAe",
      "metadata": {
        "id": "ry4Vr1FtxTAe"
      },
      "outputs": [],
      "source": [
        "def full_backprop(yhat, y, dense_caches, conv_caches, conv_dims, A_next):\n",
        "    '''\n",
        "    Backprop for both the dense and convolutional sections of the nework\n",
        "\n",
        "    Args:\n",
        "        yhat ((1, m)): vector of activations of output layer for each example\n",
        "        y ((1, m)): vector of labels for each training example\n",
        "        caches (list): list of each layer's cache dictionary\n",
        "          cache (dict): Python dictionary containing\n",
        "            A_prev ((m, n_H, n_W, n_C)): previous activation matrices\n",
        "            filters ((n_filters, n_f, n_f, n_C)): filters\n",
        "            biases (n_filters, 1): bias term for each filter\n",
        "            stride (int): stride size\n",
        "            padding (int): padding size\n",
        "        conv_dims (dict): dict containing either 'conv', or 'max_pool' corresponding to a sub-dict\n",
        "            conv (dict): dict with keys 'n_f', 'n_s', 'n_p', 'n_filters'\n",
        "                n_f (int): kernel/filter size\n",
        "                n_s (int): stride size\n",
        "                n_p (int): padding size\n",
        "                n_filters (int): number of filters\n",
        "            max_pool (dict): dict with keys 'pool_size', 'n_s'\n",
        "                pool_size (int): max pooling size\n",
        "                n_s (int): max pooling stride\n",
        "\n",
        "    Returns:\n",
        "        dense_grads (dict): dict containg keys 'W + str(l)' and 'b + str(l)\n",
        "        conv_grads (dict): dict containing keys 'W + str(l)' and 'b + str(l)\n",
        "    '''\n",
        "\n",
        "    # Full dense backprop\n",
        "    dense_grads = dense_backprop(yhat, y, dense_caches)\n",
        "\n",
        "    # Get gradient for output of dense section and reshape back to 4D\n",
        "    shape = A_next.shape\n",
        "    dA_next = dense_grads['dA0'].T.reshape(shape)\n",
        "\n",
        "    conv_grads = {}\n",
        "\n",
        "    # Create a mapping from cache index to conv layer number used in params\n",
        "    conv_layer_numbers = []\n",
        "    current_conv_l = 1\n",
        "    for dim_type in conv_dims:\n",
        "\n",
        "      if 'conv' in dim_type:\n",
        "        conv_layer_numbers.append(current_conv_l)\n",
        "        current_conv_l += 1\n",
        "      else: # For pooling layers, no conv param number\n",
        "        conv_layer_numbers.append(None)\n",
        "\n",
        "    # Iterate through conv_caches in reverse order for backpropagation\n",
        "    dA_prev = None \n",
        "    for cache_idx in range(len(conv_caches) - 1, -1, -1):\n",
        "      conv_cache = conv_caches[cache_idx]\n",
        "      dim_type = list(conv_dims.keys())[cache_idx]\n",
        "\n",
        "      # Change exact match to 'in' check\n",
        "      if 'conv' in dim_type: \n",
        "          conv_layer_num = conv_layer_numbers[cache_idx]\n",
        "          dA_prev, dW, db = vec_conv_back_prop(dA_next, conv_cache)\n",
        "          conv_grads['dW' + str(conv_layer_num)] = dW\n",
        "          conv_grads['db' + str(conv_layer_num)] = db\n",
        "\n",
        "      elif 'pool' in dim_type:\n",
        "          A_prev, pool_size, n_s = conv_cache['A_prev'], conv_cache['pool_size'], conv_cache['stride']\n",
        "          dA_prev = vec_max_pool_backprop(dA_next, A_prev, pool_size, n_s)\n",
        "\n",
        "      # Update dA_next\n",
        "      dA_next = dA_prev\n",
        "\n",
        "    # Return gradient dictionaries\n",
        "    return conv_grads, dense_grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "gsrck3Sws9iv",
      "metadata": {
        "id": "gsrck3Sws9iv"
      },
      "outputs": [],
      "source": [
        "def Adam(params, grads, S, V, iter, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "    '''\n",
        "    Adam optimization algorithm, combining both RMSprop and gradient descent with momentum, as well as bias correction\n",
        "\n",
        "    Args:\n",
        "      parameters (tuple): tuple of conv_params and dense_params dictionaries\n",
        "        conv_params (dict): dict containg keys 'Wl' (filters of layer l), and 'bl' (biases of layer l)\n",
        "        dense_params (dict): dict with keys 'Wl' (weights of layer l) and 'bl' (biases of layer l)\n",
        "      grads (tuple): tuple of conv_grads and dense_grads dicts\n",
        "        conv_grads (dict): dict with keys 'dWl' and 'dbl' (i.e., the partial derivative of each parameter)\n",
        "        dense_grads (dict): dict with keys 'dWl' and 'dbl' (i.e., the partial derivative of each parameter)\n",
        "      S (tuple): contains exponential moving average of squared gradients dictionaries of conv_S and dense_S\n",
        "      V (tuple): contains exponential moving average of gradients dictionaries of conv_V and dense_V\n",
        "\n",
        "    Returns:\n",
        "      parameters (tuple): updated tuple of conv_params and dense_params dictionaries\n",
        "        conv_params (dict): updated dict containg keys 'Wl' (filters of layer l), and 'bl' (biases of layer l)\n",
        "        dense_params (dict): updated dict with keys 'Wl' (weights of layer l) and 'bl' (biases of layer l)\n",
        "      S (tuple): contains exponential moving average of squared gradients dictionaries of conv_S and dense_S\n",
        "      V (tuple): contains exponential moving average of gradients dictionaries of conv_V and dense_V\n",
        "    '''\n",
        "\n",
        "    # Unpack tuples\n",
        "    (conv_params, dense_params) = params\n",
        "    (conv_grads, dense_grads) = grads\n",
        "    (conv_S, dense_S) = S\n",
        "    (conv_V, dense_V) = V\n",
        "\n",
        "    # Iterate over all dense_params\n",
        "    L = len(dense_params)//2\n",
        "    for l in range(1, L+1):\n",
        "\n",
        "        # Get gradients\n",
        "        dWl, dbl = dense_grads['dW'+str(l)], dense_grads['db'+str(l)]\n",
        "\n",
        "        # Update velocity terms\n",
        "        dense_V['dW'+str(l)] = (beta1 * dense_V['dW'+str(l)]) + ((1-beta1) * dWl)\n",
        "        dense_V['db'+str(l)] = (beta1 * dense_V['db'+str(l)]) + ((1-beta1) * dbl)\n",
        "\n",
        "        # Update squared-gradient terms\n",
        "        dense_S['dW' + str(l)] = (beta2 * dense_S['dW' + str(l)]) + ((1 - beta2) * np.square(dWl))\n",
        "        dense_S['db' + str(l)] = (beta2 * dense_S['db' + str(l)]) + ((1 - beta2) * np.square(dbl))\n",
        "\n",
        "        # Bias correction\n",
        "        vdW_corrected = dense_V['dW'+str(l)] / (1 - (beta1 ** iter))\n",
        "        vdb_corrected = dense_V['db'+str(l)] / (1 - (beta1 ** iter))\n",
        "\n",
        "        sdW_corrected = dense_S['dW' + str(l)] / (1 - (beta2 ** iter))\n",
        "        sdb_corrected = dense_S['db' + str(l)] / (1 - (beta2 ** iter))\n",
        "\n",
        "        # Update Parameters\n",
        "        dense_params['W'+str(l)] -= (alpha * vdW_corrected) / (np.sqrt(sdW_corrected)+epsilon)\n",
        "        dense_params['b'+str(l)] -= (alpha * vdb_corrected) / (np.sqrt(sdb_corrected)+epsilon)\n",
        "\n",
        "  # Iterate over all conv_params\n",
        "    L = len(conv_params)//2\n",
        "    for l in range(1, L+1):\n",
        "\n",
        "        # Get gradients\n",
        "        dWl, dbl = conv_grads['dW'+str(l)], conv_grads['db'+str(l)]\n",
        "\n",
        "        # Update velocity terms\n",
        "        conv_V['dW'+str(l)] = (beta1 * conv_V['dW'+str(l)]) + ((1-beta1) * dWl)\n",
        "        conv_V['db'+str(l)] = (beta1 * conv_V['db'+str(l)]) + ((1-beta1) * dbl)\n",
        "\n",
        "        # Update squared-gradient terms\n",
        "        conv_S['dW' + str(l)] = (beta2 * conv_S['dW' + str(l)]) + ((1 - beta2) * np.square(dWl))\n",
        "        conv_S['db' + str(l)] = (beta2 * conv_S['db' + str(l)]) + ((1 - beta2) * np.square(dbl))\n",
        "\n",
        "        # Bias correction\n",
        "        vdW_corrected = conv_V['dW'+str(l)] / (1 - (beta1 ** iter))\n",
        "        vdb_corrected = conv_V['db'+str(l)] / (1 - (beta1 ** iter))\n",
        "\n",
        "        sdW_corrected = conv_S['dW' + str(l)] / (1 - (beta2 ** iter))\n",
        "        sdb_corrected = conv_S['db' + str(l)] / (1 - (beta2 ** iter))\n",
        "\n",
        "        # Update Parameters\n",
        "        conv_params['W'+str(l)] -= (alpha * vdW_corrected) / (np.sqrt(sdW_corrected)+epsilon)\n",
        "        conv_params['b'+str(l)] -= (alpha * vdb_corrected) / (np.sqrt(sdb_corrected)+epsilon)\n",
        "\n",
        "    # Repack tuples\n",
        "    params = (conv_params, dense_params)\n",
        "    S = (conv_S, dense_S)\n",
        "    V = (conv_V, dense_V)\n",
        "\n",
        "    return params, S, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "0xL_V05r0xNJ",
      "metadata": {
        "id": "0xL_V05r0xNJ"
      },
      "outputs": [],
      "source": [
        "def initialize_adam(params):\n",
        "\n",
        "  # Initialize adam\n",
        "  (conv_params, dense_params) = params\n",
        "  dense_S, conv_S, dense_V, conv_V = {}, {}, {}, {}\n",
        "  S, V = (conv_S, dense_S), (conv_V, dense_V)\n",
        "\n",
        "  # Loop over dense params\n",
        "  L = len(dense_params)//2\n",
        "  for l in range(1, L+1):\n",
        "\n",
        "    # RMS prop terms\n",
        "    dense_S['dW'+str(l)] = np.zeros_like(dense_params['W'+str(l)]).astype(np.float32)\n",
        "    dense_S['db'+str(l)] = np.zeros_like(dense_params['b'+str(l)]).astype(np.float32)\n",
        "\n",
        "    # Momentum terms\n",
        "    dense_V['dW'+str(l)] = np.zeros_like(dense_params['W'+str(l)]).astype(np.float32)\n",
        "    dense_V['db'+str(l)] = np.zeros_like(dense_params['b'+str(l)]).astype(np.float32)\n",
        "\n",
        "  L = len(conv_params)//2\n",
        "  for l in range(1, L+1):\n",
        "    # RMS prop terms\n",
        "    conv_S['dW'+str(l)] = np.zeros_like(conv_params['W'+str(l)]).astype(np.float32)\n",
        "    conv_S['db'+str(l)] = np.zeros_like(conv_params['b'+str(l)]).astype(np.float32)\n",
        "\n",
        "    # Momentum terms\n",
        "    conv_V['dW'+str(l)] = np.zeros_like(conv_params['W'+str(l)]).astype(np.float32)\n",
        "    conv_V['db'+str(l)] = np.zeros_like(conv_params['b'+str(l)]).astype(np.float32)\n",
        "\n",
        "  S, V = (conv_S, dense_S), (conv_V, dense_V)\n",
        "\n",
        "  return S, V\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "FlZ56QoVr4Ds",
      "metadata": {
        "id": "FlZ56QoVr4Ds"
      },
      "outputs": [],
      "source": [
        "def get_learning_rate(epoch, initial_lr=0.001):\n",
        "    if epoch < 10:\n",
        "        return initial_lr\n",
        "    elif epoch < 20:\n",
        "        return initial_lr * 0.1\n",
        "    else:\n",
        "        return initial_lr * 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "a_aDEG4mypSg",
      "metadata": {
        "id": "a_aDEG4mypSg"
      },
      "outputs": [],
      "source": [
        "def train(X, y, X_test, y_test, dims, epochs, batch_size=64):\n",
        "    '''\n",
        "    Forward and backprop to train CNN model\n",
        "\n",
        "    Args:\n",
        "        X ((m, n_H, n_W, n_C)): inputs\n",
        "    '''\n",
        "\n",
        "    (conv_dims, dense_dims) = dims\n",
        "    conv_params = initialize_convolution(X, conv_dims)\n",
        "    dense_params = initialize_parameters(X, dense_dims, conv_params, conv_dims)\n",
        "    params = (conv_params, dense_params)\n",
        "    S, V = initialize_adam(params)\n",
        "\n",
        "    # Empty list to record cost\n",
        "    cost_history_train, cost_history_test = [], []\n",
        "    m = X.shape[0]\n",
        "\n",
        "    iter = 0\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "      permutation = np.random.permutation(m)\n",
        "      X_shuffled, y_shuffled = X[permutation], y[:, permutation]\n",
        "      epoch_cost_train = 0\n",
        "      num_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "      for i in range(num_batches):\n",
        "        begin = i * batch_size\n",
        "        end = min(begin + batch_size, m)\n",
        "\n",
        "        X_batch, y_batch = X_shuffled[begin:end], y_shuffled[:, begin:end]\n",
        "\n",
        "        # Full forward prop\n",
        "        cost, yhat, dense_caches, conv_caches, A_next = full_forwardprop(X_batch, y_batch, conv_dims, dense_dims, params)\n",
        "        epoch_cost_train += cost\n",
        "\n",
        "        # Full backprop\n",
        "        conv_grads, dense_grads = full_backprop(yhat, y_batch, dense_caches, conv_caches, conv_dims, A_next)\n",
        "\n",
        "        iter += 1\n",
        "        # Adam optimization algorithm\n",
        "        lr = get_learning_rate(epoch)\n",
        "        params, S, V = Adam(params, (conv_grads, dense_grads), S, V, iter, alpha=lr)\n",
        "        del conv_caches, dense_caches, A_next\n",
        "\n",
        "      cost_history_train.append(epoch_cost_train / num_batches)\n",
        "\n",
        "      cost_test, _ = predict(X_test, y_test, params, dims)\n",
        "      cost_history_test.append(cost_test)\n",
        "\n",
        "      cost_history = (cost_history_train, cost_history_test)\n",
        "\n",
        "    return params, cost_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "gl4TYkI8-_7T",
      "metadata": {
        "id": "gl4TYkI8-_7T"
      },
      "outputs": [],
      "source": [
        "def conv_forward_no_cache(A_prev, filters, biases, n_s, n_p):\n",
        "\n",
        "    # Get filter shape and activation dimensions\n",
        "    n_f, n_filters = filters.shape[1], filters.shape[0]\n",
        "    (m, n_H, n_W, n_C) = A_prev.shape\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    n_H_ = int(np.floor((n_H + (2 * n_p) - n_f) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W + (2 * n_p) - n_f) / n_s)) + 1\n",
        "\n",
        "    # Apply padding\n",
        "    padded_shape = (m, n_H + (2 * n_p), n_W + (2 * n_p), n_C)\n",
        "    A_prev_pad = get_buffer(\"pred_conv_pad\", padded_shape, A_prev.dtype)\n",
        "    A_prev_pad[:, n_p:n_p+n_H, n_p:n_p+n_W, :] = A_prev\n",
        "\n",
        "    # Create sliding windows view\n",
        "    shape = (m, n_H_, n_W_, n_f, n_f, n_C)\n",
        "    strides = (A_prev_pad.strides[0], n_s * A_prev_pad.strides[1], n_s * A_prev_pad.strides[2],\n",
        "               A_prev_pad.strides[1], A_prev_pad.strides[2], A_prev_pad.strides[3])\n",
        "    windows = np.lib.stride_tricks.as_strided(A_prev_pad, shape=shape, strides=strides)\n",
        "\n",
        "    # Convolution with einsum\n",
        "    Z = np.einsum('mhwfgc,dfgc->mhwd', windows, filters) + biases\n",
        "\n",
        "    # ReLU activation\n",
        "    A_next = np.maximum(Z, 0)\n",
        "\n",
        "    return A_next\n",
        "\n",
        "def max_pool_forward_no_cache(A_prev, pool_size, n_s):\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    (m, n_H, n_W, n_C) = A_prev.shape\n",
        "    n_H_ = int(np.floor((n_H - pool_size) / n_s)) + 1\n",
        "    n_W_ = int(np.floor((n_W - pool_size) / n_s)) + 1\n",
        "\n",
        "    # Create sliding windows view\n",
        "    shape = (m, n_H_, n_W_, pool_size, pool_size, n_C)\n",
        "    strides = (A_prev.strides[0],\n",
        "               n_s * A_prev.strides[1],\n",
        "               n_s * A_prev.strides[2],\n",
        "               A_prev.strides[1],\n",
        "               A_prev.strides[2],\n",
        "               A_prev.strides[3])\n",
        "    windows = np.lib.stride_tricks.as_strided(A_prev, shape, strides)\n",
        "\n",
        "    # Max pooling\n",
        "    A_next = np.max(windows.reshape(m, n_H_, n_W_, pool_size * pool_size, n_C), axis=3)\n",
        "\n",
        "    return A_next\n",
        "\n",
        "def dense_forward_no_cache(conv_prev, y, parameters):\n",
        "\n",
        "    # Flatten conv output\n",
        "    m = conv_prev.shape[0]\n",
        "    A_prev = conv_prev.reshape(m, -1).T\n",
        "\n",
        "    # Forward through hidden layers\n",
        "    L = len(parameters) // 2\n",
        "    for l in range(1, L):\n",
        "        Z = np.dot(parameters['W' + str(l)], A_prev) + parameters['b' + str(l)]\n",
        "        A_prev = np.maximum(Z, 0)  # ReLU\n",
        "\n",
        "    # Output layer\n",
        "    Z = np.dot(parameters['W' + str(L)], A_prev) + parameters['b' + str(L)]\n",
        "    yhat = softmax(Z)\n",
        "\n",
        "    # Calculate cost\n",
        "    cost = categorical_cross_entropy_cost(yhat, y)\n",
        "\n",
        "    return cost, yhat\n",
        "\n",
        "def predict(X, y, params, dims):\n",
        "    '''\n",
        "    Efficient forward prop for prediction only (no caching for backprop)\n",
        "\n",
        "    Args:\n",
        "        X ((m, n_H, n_W, n_C)): input images\n",
        "        y ((1, m)): labels\n",
        "        params (tuple): (conv_params, dense_params)\n",
        "        dims (tuple): (conv_dims, dense_dims)\n",
        "\n",
        "    Returns:\n",
        "        cost (float): binary cross-entropy cost\n",
        "        yhat ((1, m)): predicted probabilities\n",
        "    '''\n",
        "    (conv_params, dense_params) = params\n",
        "    (conv_dims, dense_dims) = dims\n",
        "\n",
        "    A_prev = X\n",
        "    l = 1\n",
        "\n",
        "    # Forward through conv and pooling layers\n",
        "    for dim in conv_dims:\n",
        "        if dim == 'conv' or 'conv' in dim:\n",
        "            A_next = conv_forward_no_cache(A_prev,\n",
        "                                           filters=conv_params['W' + str(l)],\n",
        "                                           biases=conv_params['b' + str(l)],\n",
        "                                           n_s=conv_dims[dim]['n_s'],\n",
        "                                           n_p=conv_dims[dim]['n_p'])\n",
        "            l += 1\n",
        "        elif dim == 'max_pool' or 'pool' in dim:\n",
        "            A_next = max_pool_forward_no_cache(A_prev,\n",
        "                                               conv_dims[dim]['pool_size'],\n",
        "                                               conv_dims[dim]['n_s'])\n",
        "        A_prev = A_next\n",
        "\n",
        "    # Forward through dense layers\n",
        "    cost, yhat = dense_forward_no_cache(A_prev, y, dense_params)\n",
        "\n",
        "    return cost, np.argmax(yhat, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "FvmfFQ0fTe1b",
      "metadata": {
        "id": "FvmfFQ0fTe1b"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(y, num_classes=10):\n",
        "\n",
        "    m = y.shape[0]\n",
        "    one_hot = np.zeros((num_classes, m))\n",
        "    one_hot[y, np.arange(m)] = 1\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "8YE9cpSdqSZF",
      "metadata": {
        "id": "8YE9cpSdqSZF"
      },
      "outputs": [],
      "source": [
        "def batched_predict_with_cleanup(X, y, params, dims, batch_size=512):\n",
        "    preds = np.zeros(X.shape[0], dtype=np.int64)\n",
        "\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        end = min(i + batch_size, X.shape[0])\n",
        "        _, yhat = predict(X[i:end], y[:, i:end], params, dims)\n",
        "        preds[i:end] = yhat\n",
        "\n",
        "        # Clear memory pool every 10 batches\n",
        "        if i % (batch_size * 10) == 0:\n",
        "            mem_pool.clear()\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "XADEVct3wUgy",
      "metadata": {
        "id": "XADEVct3wUgy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load data\n",
        "(train_X, train_y), (test_X, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reshape X to (m, n_H, n_W, n_C)\n",
        "train_X = train_X.reshape(train_X.shape[0], 28, 28, 1).astype(np.float32)\n",
        "test_X = test_X.reshape(test_X.shape[0], 28, 28, 1).astype(np.float32)\n",
        "\n",
        "# Select subset of data\n",
        "# train_X = train_X[:1000, :, :, :]\n",
        "# train_y = train_y[:1000]\n",
        "# test_X = test_X[:1000, :, :, :]\n",
        "# test_y = test_y[:1000]\n",
        "\n",
        "# Reshape y to (1, m)\n",
        "train_y = one_hot_encode(train_y)\n",
        "test_y = one_hot_encode(test_y)\n",
        "\n",
        "# Normalization\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "njacxGZ731pl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "69864c71a1a44460b97682e7ec3f1ee7",
            "5c08131231a14387b84d96725aeadd09",
            "20dda417976a49fbbd93b8769a288791",
            "77488f4deb224b3fae2e07208b9417d1",
            "3087e433bf4e4c56a0ae9bdcb0b7b48d",
            "b6ba45bbdc6d405eb95f5772c177d2ce",
            "bef2c8beffcc411495c38acea085de7d",
            "fd7c56ea48654341a6499909160e25f3",
            "96e73e8e17f54d95b0a824022f958e6e",
            "733b486714a440e8ad745bbc520a8398",
            "1b34b71725d947deb0ab9ee3d050e1d2"
          ]
        },
        "id": "njacxGZ731pl",
        "outputId": "8b98f4a4-b4b7-42c6-8262-6dcebc6fb580"
      },
      "outputs": [],
      "source": [
        "# Specify architecture\n",
        "conv_1 = {'n_f': 5, 'n_s': 1, 'n_p': 2, 'n_filters': 32}\n",
        "pool_1 = {'pool_size': 2, 'n_s': 2}\n",
        "conv_2 = {'n_f': 5, 'n_s': 1, 'n_p': 2, 'n_filters': 64}\n",
        "pool_2 = {'pool_size': 2, 'n_s': 2}\n",
        "\n",
        "conv_dims = {\n",
        "    'conv': conv_1, 'max_pool': pool_1,\n",
        "    'conv2': conv_2, 'max_pool2': pool_2\n",
        "}\n",
        "dense_dims = [1024, 10].copy()\n",
        "\n",
        "dims = (conv_dims, dense_dims)\n",
        "\n",
        "# Train network\n",
        "params, cost_history = train(train_X, train_y,\n",
        "                             test_X, test_y,\n",
        "                             dims, epochs=25, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Mkq5fYEpwyV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mkq5fYEpwyV",
        "outputId": "c8895bf5-2f77-4f1d-eec7-ce1fba3a6cd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1664"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w5Ry9ShxIdZ9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "w5Ry9ShxIdZ9",
        "outputId": "4e80eaa7-d50a-4e16-f308-2681c710101b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(cost_history[0], color='orange', label='train')\n",
        "plt.plot(cost_history[1], color='deepskyblue', label='test')\n",
        "plt.title('Train and test error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oL_xV2i2ONPW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL_xV2i2ONPW",
        "outputId": "fb51a502-9ba4-4c57-85ea-becb93e6a51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 1.0000\n",
            "Test accuracy: 0.9360\n"
          ]
        }
      ],
      "source": [
        "# Inference on training set\n",
        "yhat_train = batched_predict_with_cleanup(train_X, train_y, params, dims)\n",
        "print(f'Training accuracy: {accuracy_score(y_pred=yhat_train, y_true=np.argmax(train_y, axis=0)):.4f}')\n",
        "\n",
        "# Inference on test set\n",
        "yhat_test = batched_predict_with_cleanup(test_X, test_y, params, dims)\n",
        "print(f'Test accuracy: {accuracy_score(y_pred=yhat_test, y_true=np.argmax(test_y, axis=0)):.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b34b71725d947deb0ab9ee3d050e1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20dda417976a49fbbd93b8769a288791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd7c56ea48654341a6499909160e25f3",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96e73e8e17f54d95b0a824022f958e6e",
            "value": 10
          }
        },
        "3087e433bf4e4c56a0ae9bdcb0b7b48d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c08131231a14387b84d96725aeadd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ba45bbdc6d405eb95f5772c177d2ce",
            "placeholder": "",
            "style": "IPY_MODEL_bef2c8beffcc411495c38acea085de7d",
            "value": "100%"
          }
        },
        "69864c71a1a44460b97682e7ec3f1ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c08131231a14387b84d96725aeadd09",
              "IPY_MODEL_20dda417976a49fbbd93b8769a288791",
              "IPY_MODEL_77488f4deb224b3fae2e07208b9417d1"
            ],
            "layout": "IPY_MODEL_3087e433bf4e4c56a0ae9bdcb0b7b48d"
          }
        },
        "733b486714a440e8ad745bbc520a8398": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77488f4deb224b3fae2e07208b9417d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_733b486714a440e8ad745bbc520a8398",
            "placeholder": "",
            "style": "IPY_MODEL_1b34b71725d947deb0ab9ee3d050e1d2",
            "value": "10/10[09:30&lt;00:00,56.82s/it]"
          }
        },
        "96e73e8e17f54d95b0a824022f958e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6ba45bbdc6d405eb95f5772c177d2ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef2c8beffcc411495c38acea085de7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd7c56ea48654341a6499909160e25f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
